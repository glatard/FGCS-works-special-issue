\documentclass[preprint,3p,twocolumn]{elsarticle}


\usepackage[x11names,dvipsnames,table]{xcolor} %for use in color links
\usepackage[subrefformat=parens,labelformat=parens]{subfig}
\usepackage{svg}
\usepackage{url}
\usepackage{flushend}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{multirow}


\newcommand{\todo}[1]{\color{blue}\xspace[\emph{#1}]\xspace\color{black}}
\newcommand{\note}[1]{\color{green}\textbf{Note: }\textit{#1} \color{black}}

\renewcommand\thesubfigure{\Roman{subfigure}}

\begin{document}

\begin{frontmatter}

%% Title, authors and addresses

%% use the tnoteref command within \title for footnotes;
%% use the tnotetext command for theassociated footnote;
%% use the fnref command within \author or \address for footnotes;
%% use the fntext command for theassociated footnote;
%% use the corref command within \author for corresponding author footnotes;
%% use the cortext command for theassociated footnote;
%% use the ead command for the email address,
%% and the form \ead[url] for the home page:
%% \title{Title\tnoteref{label1}}
%% \tnotetext[label1]{}
%% \author{Name\corref{cor1}\fnref{label2}}
%% \ead{email address}
%% \ead[url]{home page}
%% \fntext[label2]{}
%% \cortext[cor1]{}
%% \address{Address\fnref{label3}}
%% \fntext[label3]{}

\title{Architectures for workflow integration in science gateways}

%% use optional labels to link authors explicitly to addresses:
%% \author[label1,label2]{}
%% \address[label1]{}
%% \address[label2]{}

\author{}

\address{}

\begin{abstract}
%% Text of abstract
  We investigate software architectures to integrate workflow engines
  in science gateways. Based on our experience with the development
  and operations of the CBRAIN and VIP science gateways, and our past
  involvement in the SHIWA project, we abstract the software
  components and interactions in 6 architectures that we compare using
  metrics measuring integration effort, robustness, extensibility,
  scalability and other specific features. \todo{a word on results}
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword

%% PACS codes here, in the form: \PACS code \sep code

%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)

\end{keyword}

\end{frontmatter}

\journal{Future Generation Computer Systems}

\maketitle

\section{Introduction}

\todo{Section still to be written}

\paragraph{Context} The question of integrating workflow engines in
science gateways can be seen at various levels, corresponding to
various definitions of workflows. One level is the SHIWA level, where
it was considered that workflow engines are aware of the DCI (and 'D'
is important because of data transfers, proxies, etc). Another level
is to remove 'D' from the definition: a workflow engine becomes a
program that submits jobs, potentially only to local clusters. It
opens a whole new class of workflow engines that we used to consider
as "applications". For instance, in neuroinformatics: Nipype, PSOM,
but also FSL through the fslsub tool. A workflow engine is not
supposed to be aware of the science gateway.  A wide-array of workflow
engines are available with specificies coming from the application
domain, available tools, etc Their integration in science gateways
becomes critical. Several of the examples presented in the
paper will be taken from medical image analysis, in particular
neuroimaging.

\paragraph{Goal} this paper reviews and compares the architectures to
integrate workflow engines in science gateways.

\paragraph{Contributions}
\begin{itemize}
\item We evaluate architectures based on our experience with existing systems
\item We propose a new architecture
\end{itemize}

\section{Workflow engines and science gateways}

\todo{This section still needs to be finished}

\subsection{Workflow engines}

In the last decade, the e-Science workflow community has developed
workflow systems to help developers access distributed infrastructures
such as clusters, grids, clouds and web services, resulting in tools
such as Askalon~\cite{fahringer2005askalon},
Hyperflow~\cite{balis2016hyperflow}, MOTEUR~\cite{GLAT-08i},
Pegasus~\cite{deelman2005pegasus,Deelman201517},
Swift~\cite{zhao2007swift}, Taverna~\cite{oinn2004taverna},
Triana~\cite{taylor2007triana}, VisTrails~\cite{callahan2006managing},
WS-PGRADE/gUSE~\cite{Kacsuk2012}\footnote{\todo{WS-PGRADE/gUSE is the
    science gateway, check what the engine is called now}}, etc. Such
workflow engines usually describe applications in a  language
that offers parallel data and control flow constructs, visual edition
features, links with domain-specific tool repositories, provenance
recording, etc.
% Descriptions and experiments
%conducted with e-Science workflow engines were published in journals
%such as Future Generation Computer Systems and conference venues such
%as WORKS.

At the same time, specific toolboxes were emerging in various
scientific domains to facilitate the assembly of software components
in consistent pipelines. In neuroimaging, our primary domain of
interest, tools such as Nipype~\cite{gorgolewski2011nipype},
PSOM~\cite{bellec2012pipeline}, SPM~\cite{ashburner2011spm} and
FSL~\cite{Jenkinson2012782} provide abstractions and functions to
handle the data and computing flow between processes implemented in a
variety of programming languages. Such tools were interfaced to
computing systems, in particular clusters, to create tasks, handle
their dependencies, and execute them. For instance, FSL can launch
tasks on SGE through its \texttt{fsl\_sub} tool, Nipype has execution
plugins for S/OGE, Torque, IPython, ssh and multi-processor servers,
and PSOM is interfaced to Torque, SGE, MOAB, LSF and Condor. Some of
these tools also support advanced features such as provenance tracking
(Nipype, PSOM), redundancy detection across analyses to avoid
re-computation (PSOM), and so on. A wide-array of workflows have been
implemented using these pipelines and are now widely shared across
neuroimaging groups world-wide. \todo{Provide more context on that?}
These domain-specific engines represent a tremendous opportunity for
science gateways to leverage existing tools and applications. They
nicely complement e-Science engines that are more oriented towards the
exploitation of distributed computing infrastructures, in particular
grids and clouds.

We are looking for software architectures that are able to integrate
e-Science and domain-specific workflow engines in science
gateways. For the sake of the analysis conducted in this paper, we
define a \emph{workflow engine} (also abbreviated \emph{engine}) as a
software that submits interdependent computing \emph{tasks} to an
infrastructure (local server, cluster, grid or cloud) based on a
workflow description (a.k.a \emph{workflow}) and using input data that
may be files, data base entries, or simple parameter values. Although
simplistic, this definition covers both e-Science and domain-specific
engines. Some workflow engines, usually e-Science ones, may transfer
data across the infrastructure, and others, usually domain-specific
ones, may leave it to external processes. Workflows may be expressed
in any language, including high-level XML or JSON dialects such as
\texttt{Scufl} or \texttt{Hyperflow}, and low-level scripts such as
\texttt{bash}.  \todo{Mention other workflow definitions,
  e.g. abstract/concrete, etc?} \todo{Use ttt everywhere for technical
  terms (ssh, etc)?}

\subsection{Science gateways}

Science gateways are ecosystems of software tools and services to
access data and tools deployed on distributed infrastructures. They
are used to share resources in a community and to provide performance
through facilitated access to storage and computing power. They are
usually accessible through a web interface that helps users manage
access rights, data transfers, task execution and authentication on
multiple computing and storage locations. Workflow engines are of
course part of this ecosystem as core components to implement and
execute applications.

% Software properties: integration effort, extensibility, robustness,
% scalability, specific features

Integration between workflow engines and science gateways varies
across systems. Some science gateways may be tailored to a particular
workflow engine that manages critical functions such as task
execution, data transfers and authentication. Other gateways may be
more general and host applications executed by different types of
engines. Extensibility is an important property of such integration:
new workflows are added frequently, different types and versions of
workflow engines may be integrated over time, and different kinds of
infrastructure may be covered.

Scalability is also an important concern, since science gateways are
multi-user systems, manage substantial amounts of data and execute
computationally-intensive analyses. For this purpose, science gateways
may include different instances of the same engine type and implement
some load-balancing policy among them. They may also enforce
scheduling policies on the infrastructure, e.g. to ensure fairness
among users~\cite{FERR-14} or to improve
fault-tolerance~\cite{FERR-13}. \todo{Remove these self-citations or
  cite more works on this topic.}

Robustness is a key part of science gateway user experience. In this
respect, the multiplicity of software components and functions is a
challenge as it often leads to complex architectures that are
therefore prone to failure. To offer good user experience, science
gateways should remain as transparent as possible, which requires
robustness. 

Specific features may also be available in science
gateways, such as data vizualisation and quality control, workflow
edition, debugging instruments, social tools among users, etc.

Various science gateways have been developed in the last years,
including science gateway frameworks used as building blocks to
assemble science gateways. The main frameworks are
WS-PGRADE/gUSE~\cite{Kacsuk2012}, the Catania Science Gateway
Framework~\cite{Ardizzone2012} and Apache
Airavata~\cite{marru2011apache} \todo{According to
  https://airavata.apache.org, Genapp is based on Airavata, we could
  refer to it somewhere}. Numerous science gateway instances were
built using such frameworks, in various disciplines. Other gateway
instances were also built independently from any framework, using
regular web development tools and various libraries to manage
distributed systems.

This paper builds on experience from the development and sustained
operations of CBRAIN (2008-now), the Virtual Imaging Platform
(2009-now), and on our involvement with the
SHIWA\footnote{\url{http://www.shiwa-workflow.eu}} European project
(2010-2012) that built the SHIWA Simulation Platform.

CBRAIN\footnote{\url{http://cbrain.mcgill.ca}}~\cite{SHER-14} is an
open-source, web-based collaborative platform addressing the
challenges of data-heavy, computation-intensive neuroimaging
research. It offers transparent web-based access to remote data
sources, distributed computing sites, and an array of processing and
visualization tools, within a secure environment. CBRAIN is deployed
at a wide range of computing sites, including nine national HPC
centers in Canada, one in Korea, one in Germany, and on numerous local
servers. As September 2015, CBRAIN has served over 370 users across 50
cities in 19 countries who produced several high-impact results in the
field of neurosciences.

The Virtual Imaging Platform
(VIP\footnote{\url{http://www.creatis.insa-lyon.fr/vip}})~\cite{GLAT-13}
is a web portal for medical simulation and image data analysis. It
leverages computing and storage resources available in the biomed
Virtual Organization of the European Grid Infrastructure (EGI) to
offer an open service to academic researchers worldwide. VIP
completely masks the infrastructure to enable a transparent user
experience. It uses the MOTEUR workflow engine~\cite{GLAT-13} and the
DIRAC pilot-job framework to execute applications on EGI. Almost 900
users were registered in VIP in April 2016 and the average CPU
consumption between January 2013 and March 2016 was 35 CPU years per
month.

\todo{SHIWA Simulation Platform.}

\subsection{Infrastructures}


The infrastructure consists of the computing and storage resources
involved in the workflow execution, and the software services used to
access these resources. Infrastructures can be servers, clusters,
grids or clouds. Some workflow engines may assume specific
characteristics about the infrastructure, such as the presence of a
shared file system between the computing nodes.

\section{Architectures}
\label{sec:architectures}

The architectures are diagramed in Figure~\ref{fig:architectures}
using the graphical notations shown in
Figure~\ref{fig:notations}. Architectures are described from their
main software \emph{components} and \emph{interactions}. Software
components include science gateway and infrastructure in all
architectures while workflow service, workflow pool and agent are
involved in some architectures. The workflow engine itself is
represented by a specific symbol with dotted lines. Software
interactions among these components are represented with
arrows. \emph{Abstract} interactions are specific types of
interactions that may be implemented by various different software
interactions. They are represented with dotted arrows and labeled with
 \texttt{*}. An architecture that has an abstract interaction is an
abstract architecture. Red color is used to represent the components
and interactions that are specific to workflow execution, i.e. that
are not involved in any other process. Tasks refer to computing tasks
that are created by the workflow engine and executed on the
infrastructure. Data represents any type of file, or database that is
involved in the workflow execution and stored on the infrastructure
while the workflow executes. It does not cover workflow parameters
such as strings, numbers, etc. The remainder of this section describes
the different types of interactions involved in the architectures, and
details each architecture.

%http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4782949

\begin{figure}
\centering
\def\svgwidth{\columnwidth}
\input{figures/notations.pdf_tex}
\caption{Graphical notations}
\label{fig:notations}
\end{figure}

\begin{figure*}
\centering
\hspace*{0.2\columnwidth}
\subfloat[Tight integration]{
\def\svgwidth{0.6\columnwidth}
\input{figures/tight.pdf_tex}
\label{archi:tight}
}
\hfill
\subfloat[Service invocation]{
\def\svgwidth{0.6\columnwidth}
\input{figures/service.pdf_tex}
\label{archi:service}
\hspace*{0.2\columnwidth}
}\\
\hspace*{0.2\columnwidth}
\subfloat[Sub-tasking]{
\def\svgwidth{0.6\columnwidth}
\input{figures/sub-task.pdf_tex}
\label{archi:sub-task}
}
\hfill
\subfloat[Pool]{
\def\svgwidth{0.6\columnwidth}
\input{figures/agent.pdf_tex}
\label{archi:agent}
\hspace*{0.2\columnwidth}
}\\
\subfloat[Nested workflows. Left: abstract model. Right: instantiation with service invocation.]{
\def\svgwidth{0.9\columnwidth}
\input{figures/nested-1.pdf_tex}
\def\svgwidth{0.9\columnwidth}
\input{figures/nested-2.pdf_tex}
\label{archi:nested}
}\\
\subfloat[Workflow import. Left: abstract model. Right: instantiation with service invocation.]{
\def\svgwidth{0.5\columnwidth}
\input{figures/import-1.pdf_tex}
\hfill
\def\svgwidth{0.5\columnwidth}
\input{figures/import-2.pdf_tex}
\label{archi:import}
}
\caption{Architectures}
\label{fig:architectures}
\end{figure*}

\subsection{Interactions}

The interactions involved in the architectures are described below and
labeled consistently with the notations used on
Figure~\ref{fig:architectures}.

\begin{enumerate}[leftmargin=0cm,itemindent=0.6cm,label=\texttt{(\alph*)}]

\item Workflow integration: consists in adding a new workflow to the
  system so that users can execute it. It is triggered by an
  administrator of the science gateway and it results in an interface,
  for instance a web form, where users can enter the parameters of the
  workflow to be executed. The interaction has two aspects:
  (\texttt{a$_1$}) the programs used in the workflow are installed on
  the infrastructure, which may or may not require administrative
  privileges on the infrastructure; (\texttt{a$_2$}) the workflow is
  configured in the science gateway so that it becomes available to
  users. Note that integrating a workflow is not the same process as
  integrating a workflow \emph{engine}.
\item Task control: operations to manage tasks on the infrastructure,
  including: authentication, submission, monitoring, termination,
  deletion, etc. Controlling tasks requires to deal with the
  heterogeneous batch managers and meta-schedulers that might be
  available on the infrastructure. When the infrastructure is a grid
  or a cloud, it is for instance implemented using libraries such as
  SAGA, DRMAA, OCCI and similar initiatives \todo{refs needed}.
\item Data control: operations to manage data on the infrastructure,
  such as: upload, download, deletion, browsing, replication, caching,
  etc. Data movements can be triggered by the user in the science
  gateway (\texttt{$c_1$}), to upload input data or download processed
  data. They can also be performed by the workflow engine
  (\texttt{$c_2$}), to transfer data across the infrastructure. The
  infrastructure might offer various data storage backends with
  heterogeneous interfaces. Tools and services such as
  JSAGA~\cite{reynaud2010uniform} or Data Avenue~\cite{hajnal2014data}
  can be used to homogeneize these interfaces.
\item Workflow control: operations to execute a workflow with an
  engine, including: workflow submission, monitoring, termination,
  etc. Workflow control can be coarse-grained (a.k.a. black box) or
  fine-grained (white box). In a coarse-grained model, the various
  tasks created by a workflow execution are masked and the user only
  has a global view of the workflow execution. In a fine-grained
  model, user is exposed to the workflow topology, i.e. to the outputs
  of the individual tasks, their statuses and so on.
\item Sub-task control: operations used by tasks to submit sub-tasks
  on the infrastructure, including: submission, monitoring,
  termination, deletion, etc. Sub-task control is similar to
  interaction \texttt{b}, except that information about the parent
  task which submitted a sub-task is usually available and used for
  additional control. For instance, the parent task may wait for all
  its sub-tasks to finish before finishing, and conversely all the
  sub-tasks may be killed if the parent task is killed.
\item Pool-agent: specific to the architecture described
  in Section~\ref{sec:pool}. This is an interaction used when agents retrieve
  work from a central pool. It covers agent registration and
  de-registration to the pool, protocols to send work from the pool to
  the agent, mechanisms to update work status, and so on. 
\item Workflow conversion: translation from one workflow language to
  another one. This interaction may not be available or implementable
  for every workflow language. It has been developed mostly for
  well-structured and relatively simple workflow language such as between GWorkflowDL
  and Scufl~\cite{OLAB-09} and between the 4 languages that were involved in the
  SHIWA initiative. In SHIWA, workflow conversion is done through an
  intermediate representation, the Interoperable Workflow Intermediate
  Representation~\cite{plankensteiner-montagnat-etal:2011}, which
  allows to convert among $n$ workflow languages using $2n$
  interactions instead of $n^2$.
\end{enumerate}


\subsection{Tight integration}

See Figure~\subref*{archi:tight}. The workflow engine is tightly
integrated with the science gateway, which means that it is deployed
on the same machine and potentially shares code, libraries and other
software components with the science gateway. For instance, the
workflow engine might be a portlet in a Liferay portal or a controller
in a Ruby on Rails application. The workflow engine and the science
gateway usually share a database where application, users and other
resources are stored. In this model, task and data control are both
initiated from the science gateway. Interactions \texttt{b} and
\texttt{c$_2$} are initiated from the workflow engine while
\texttt{c$_1$} comes from other parts of the science gateway, for
instance a data management interface. As in any other model, the
installation of new workflows in the science gateway (\texttt{a$_2$})
and infrastructure (\texttt{a$_1$}) is done by an administrator, for
security reasons. This is the model adopted in the Catania Science
Gateway Framework~\cite{Ardizzone2012} (see specific documentation on
workflows\footnote{\url{http://bit.ly/1oQrzvQ}}),
CIPRES~\cite{miller2010creating} and LONI Pipeline
Environment~\cite{dinov2009efficient}.
\todo{Add description of a real system.}


\subsection{Service invocation}

\begin{figure*}
\centering
\def\svgwidth{1.5\columnwidth}
\input{figures/VIP.pdf_tex}
\caption{Architecture of the Virtual Imaging Platform that integrates
  the MOTEUR engine through service invocation.}
\label{fig:vip-architecture}
\end{figure*}

See Figure~\subref*{archi:service}. The workflow engine is available
externally to the science gateway, in a service. The science gateway
controls the service through a specific interaction (\texttt{d}) that
might be implemented as a web-service call (e.g. RESTful or SOAP), as
a command-line or as any other method that offers a well-defined
interface to the workflow engine. The workflow engine might be invoked
either as a black box that completely masks the infrastructure and
tasks, or as a white box that allows for some interaction with
them. The workflow engine is responsible for controlling the tasks on
the infrastructure (\texttt{b}) and for performing the required data
transfers to execute them (\texttt{c$_2$}). User data is usually
managed through the science gateway (\texttt{c$_1$}), although it
might as well be delivered by the workflow engine directly to the
user.

This architecture is largely adopted, in systems such as Apache
Airvata~\cite{marru2011apache}, Vine
Toolkit~\cite{DBLP:journals/scpe/SzejnfeldDKKKKLPTWDNW10}, Virtual
Imaging Platform~\cite{GLAT-13}, the WS-PGRADE/gUSE
framework~\cite{Kacsuk2012} and the numerous science gateway instances
that rely on
WS-PGRADE/gUSE~\cite{kacsuk2014science}. Figure~\ref{fig:vip-architecture}
shows the architecture of the Virtual Imaging Platform, where the
MOTEUR workflow engine~\cite{GLAT-08i} is invoked as a service at step
\texttt{3} (interaction \texttt{d} on
Figure~\ref{fig:architectures}). Step \texttt{2} on
Figure~\ref{fig:vip-architecture} corresponds to interaction
\texttt{c$_1$}, and step \texttt{4} maps to interactions \texttt{b}
and \texttt{c$_2$} (in VIP, workflow data transfers are performed by
the tasks and embedded in their descriptions).

\subsection{Sub-tasking}

See Figure~\subref*{archi:sub-task}. The workflow engine is a particular
task that can submit sub-tasks to the science gateway through
interaction \texttt{e}. The workflow engine keeps track of the
dependencies between the sub-tasks but their execution is delegated to
the science gateway that executes them on the infrastructure through
interaction \texttt{b}. Although the science gateway has no global
vision of the workflow, it can keep track of the sub-tasks submitted
by a given task, for instance to be able to cancel them when the task
is canceled. The science gateway may also implement mechanisms to
facilitate the handling of task dependencies, for instance basic
dependency lists as available in most batch managers (see for instance
attribute \texttt{depend} of option \texttt{-W} in
Torque\footnote{\url{http://docs.adaptivecomputing.com}}).

The science gateway also transfers both user and workflow data across
the infrastructure, so that interactions \texttt{c$_1$} and
\texttt{c$_2$} are both covered by \texttt{c}. In practice, both
\texttt{c$_1$} and \texttt{c$_2$} can be implemented using the same
pieces of code.

The sub-tasking architecture is implemented in CBRAIN~\cite{SHER-14}
where it is used to integrate the PSOM workflow
engine~\cite{bellec2012pipeline} and the FSL toolkit. The CBRAIN-PSOM
integration~\cite{GLAT-16} is illustrated on
Figure~\ref{fig:cbrain-psom-architecture}. On this Figure, the science
gateway is represented by components \texttt{CBRAIN portal} and
\texttt{CBRAIN execution server} and the infrastructure consists of
\texttt{Storage servers} and \texttt{Computing cluster with shared
  file system}. Interaction \texttt{b} on
Figure~\ref{fig:architectures} is implemented by steps \texttt{4},
\texttt{5}, \texttt{7} and \texttt{8} (regular interactions with batch
manager). Interaction \texttt{c} is implemented by steps \texttt{3}
and \texttt{10}. Interaction \texttt{e} is implemented by step
\texttt{6}. The PSOM workflow engine adopts a pilot-job
architecture~\cite{turilli2015comprehensive} where the a master
coordinates workflow execution by submitting workers and establishing
direct communication channels with them. Note how this peculiar
execution model is totally supported by the sub-tasking architecture.

The CBRAIN-FSL integration is also remarkable as it allows to leverage
FSL pipelines that are written in a very low-level workflow language
(Linux executables and script) that submits tasks uniformly through a
specific tool called \texttt{fsl\_sub}. To integrate FSL in CBRAIN,
\texttt{fsl\_sub} was modified to implement interaction
\texttt{e}\footnote{See \texttt{fsl\_sub} modified script available at
  \url{https://github.com/aces/cbrain-plugins-neuro}} \todo{Add a
  diagram and maybe a code excerpt to illustrate that.}.

\begin{figure}
\def\svgwidth{\columnwidth}
\input{figures/CBRAIN-PSOM.pdf_tex}
\caption{Architecture of the CBRAIN-PSOM integration that illustrates
  the sub-tasking model (Figure extracted from~\cite{GLAT-16}). 1:
  User sends data and workflow execution request to storage server(s)
  and CBRAIN portal. 2: CBRAIN portal sends execution request to
  execution server on cluster. 3: Execution server transfers data from
  storage server(s). 4-5: Execution server starts PSOM master via task
  scheduler. 6: PSOM master submits PSOM workers to execution
  server. 7-8: Execution server starts PSOM workers through task
  scheduler. 9: PSOM master and workers execute workflow. 10.
  Execution server transfers results to storage server(s). \todo{Improve graphics}}
\label{fig:cbrain-psom-architecture}
\end{figure}


\subsection{Pool model}
\label{sec:pool}
See Figure~\subref*{archi:agent}. Workflows are submitted by the science
gateway to a pool through interaction \texttt{d}. Agents connect to
the pool asynchronously to retrieve and execute workflows through
interaction \texttt{f}. Agents may be started according to various
policies, for instance to ensure load balancing. Agents may wrap
different types of workflow engines. Workflow engine controls tasks
and data on the infrastructure through interactions \texttt{b} and
\texttt{c$_2$}, science gateway transfers user data through
interaction \texttt{c$_1$}, and administrator installs workflows
through interaction \texttt{a$_1$} and \texttt{a$_2$}.

The pool model was implemented in the SHIWA pool~\cite{ROGE-13}, see
Figure~\ref{fig:shiwa-pool-architecture}. In Figure
~\ref{fig:shiwa-pool-architecture}, interaction \texttt{d} of
Figure~\subref*{archi:agent} is implemented in 3 different types of calls
to the pool: workflow submission (\texttt{1} \& \texttt{2}), workflow
status retrieval (\texttt{a} and \texttt{b}), and workflow retrieval
(\texttt{13} \& \texttt{14}). In Figure
~\ref{fig:shiwa-pool-architecture}, interaction \texttt{f} of
Figure~\subref*{archi:agent} is implemented through 2 types of calls:
workflow instance retrieval (\texttt{4}, \texttt{5} and \texttt{6}),
and workflow instance update (\texttt{11} and \texttt{12}). Workflow
instance retrieval is used by the agents to fetch work from the
pool. Workflow instance update is used by the agents to update
workflow statuses. In the SHIWA pool, agents can wrap different types
of workflow engines to execute workflows expressed with different
languages. Calls \texttt{0}, \texttt{7}, \texttt{8} and \texttt{9} on
Figure~\ref{fig:shiwa-pool-architecture} are used by workflow engine
plugins to declare their supported language and launch engines, and by
workflow engines to report their status to the agent. These calls are
specific to the SHIWA Pool implementation of the \texttt{agent}
component and therefore have no corresponding representation in
Figure~\subref*{archi:agent}.

\begin{figure*}
\centering
\includegraphics[width=1.5\columnwidth]{figures/pool-interactions.pdf}
\caption{Architecture of the SHIWA pool (Figure reproduced
  from~\cite{ROGE-13}). Circle-terminated arrows indicate messages
  that are broadcast to all pool clients.}
\label{fig:shiwa-pool-architecture}
\end{figure*}


\subsection{Nested workflows}

See Figure~\subref*{archi:nested}. In nested workflows
(Figure~\subref*{archi:nested}-Left), a task of a \emph{parent} workflow
executed by the \emph{parent} engine is itself a workflow, called
\emph{child} workflow, that is executed by a \emph{child} engine. The
parent and child engines might use different workflow description
languages. They might also execute workflows on different
infrastructures. The parent workflow is also called meta-workflow. The
science gateway communicates with the parent engine through
interaction \texttt{*$_1$}. The science gateway also communicate with
the infrastructure to transfer user data through abstract interactions
\texttt{*$_2$} and \texttt{*$_3$}. Both workflow engines communicate
with the infrastructure through abstract interactions as well,
\texttt{*$_4$} and \texttt{*$_5$}. The parent engine communicates with
the child engine through abstract interaction
\texttt{*$_6$}. Administrator installs workflows in the science
gateway through interaction \texttt{a$_2$}, and installs software on
infrastructures through interactions \texttt{a$_1$}.

Nested workflows are abstract architectural patterns that can be
instantiated in the various architectures described previously. We
focus on instantiation with the service invocation model (see
Figure~\subref*{archi:nested}-Right) as this is the most used
architecture. In such an instantiation, we assume that the parent and
child workflow engines are distinct pieces of software that require
different workflow services invoked by distinct \texttt{d}
interactions. If this is not the case, then workflow services can be
collapsed in a single one with a \texttt{d} interaction with
itself. Workflow engines communicate with infrastructures using
\texttt{b} and \texttt{c$_2$}. Science gateway transfer user data to
infrastructures using \texttt{c$_1$} interactions.


Nested workflows have long been available in workflow engines, for
instance in the Taverna workbench~\cite{oinn2004taverna}. They are
also used implicitly in several platforms where workflow engines are
wrapped in workflow tasks as any other command-line tool. Nested
workflows were notably used by the SHIWA Science Gateway to implement
so-called Coarse-Grained workflow
interoperability~\cite{terstyanszky2014enabling}, i.e. to integrate
various workflow engines in a consistent
platform. Figure~\ref{fig:shiwa-architecture} shows the architecture
used in the SHIWA Science Gateway for nested workflow execution with
service invocation as represented in Figure~\subref*{archi:nested}. The
parent workflow engine is \texttt{WS-PGRADE}, invoked as a service in
the Science Gateway (step \texttt{1} on
Figure~\ref{fig:shiwa-architecture}, interaction \texttt{d} on
Figure~\subref*{archi:nested}). Ten different child engines can be used by
nested workflows, invoked through the \texttt{Submission service}
(step \texttt{2}, interaction \texttt{d}). Each of these engines can
submit jobs and transfer data to a distributed computing
infrastructure (\texttt{DCI}, step \texttt{3}, interactions \texttt{b}
and \texttt{c$_2$}). Data interactions (\texttt{c}) and application
porting ones (\texttt{a}) are not represented on
Figure~\ref{fig:shiwa-architecture}.

\begin{figure*}
\centering
\includegraphics[width=1.5\columnwidth]{figures/shiwa-science-gateway.pdf}
\caption{Nested workflow execution through SHIWA Science Gateway
  (Figure reproduced from~\cite{terstyanszky2014enabling} with
  permission of the first author).}
\label{fig:shiwa-architecture}
\end{figure*}

\subsection{Workflow import}

See Figure~\subref*{archi:import}. This is an abstract model that we
instantiate with the service invocation architecture for
consistency. Workflows are integrated in the science gateway through
format conversion from a native format to the science gateway
format. This was implemented in the SHIWA Science Gateway through
the IWIR language that provided a common language for portability
across grid workflow
systems~\cite{plankensteiner-prodan-etal:2013}.

\todo{workflow import is an offline process.}
\todo{Add description of a real system}

\section{Evaluation}

The architectures described in Section~\ref{sec:architectures} are
evaluated in Table~\ref{table:evaluation}. We use 5 main criteria to
evaluate the architectures: integration effort, robustness of workflow
execution, extensibility, scalability and other features. Criteria
break down to specific metrics where \emph{low value indicates good
  performance}. For each criterion, a total score is computed by
summing up the individual metrics. We ensure that the different
metrics in a criterion measure similar entities so that summation
makes sense. The
criteria and metrics are explained hereafter.

\subsection{Evaluation metrics}

\emph{Integration effort} measures the development required to build
the architecture. It is obtained by counting the total number of
interactions and components on the architecture diagram. It breaks
down to the following 2 metrics:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Total number of components (\texttt{I$_1$}),
\item Total number of interactions (\texttt{I$_2$}).
\end{itemize}
One may wonder whether infrastructure should be counted in
\texttt{I$_1$} since it is usually not developed by the groups who
integrate workflow engines in science gateway. However, integrating an
infrastructure in the architecture usually requires some technical
effort (e.g. account creation, software installation, etc) which is
why we keep it in the metric. The two metrics are summed to obtain the
total score for this criterion, which measures the total number of
software pieces to develop.

\emph{Robustness of workflow execution} measures the likelihood that
workflow execution fails due to errors in the components or with the
interactions in the software architecture. Note that errors coming
from the infrastructure (e.g. unavailable data or terminated tasks) or
workflows (e.g., wrong user input or application crashes) are not
covered since they do not stem directly from the software
architecture. Robustness is determined as the number of software
components and interactions that are specific to workflow execution,
i.e. not reused by other functions:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Components (\texttt{R$_1$}): number of specific components
  involved in workflow executions. Science
gateway, for instance, is \emph{not} specific to workflow execution
since it is used to authenticate users, add new workflows, transfer
user data, etc. 
\item Interactions (\texttt{R$_2$}): number of specific interactions
  involved in workflow executions.
\end{itemize}
These specific components and interactions are represented in red in
the architecture diagrams in
Figure~\ref{fig:architectures}. \texttt{R$_1$} and \texttt{R$_2$}
assume that complex architectures tend to be prone to
failure. \texttt{R$_1$} and \texttt{R$_2$}  are summed to obtain the total score for this
criterion, which measures the total number of software pieces that are
specifically involved in workflow execution.

\emph{Extensibility} measures the difficulty to replace or add
elements in the architecture. It is determined as the number of
interactions and components to modify when a new element is
added. Modification of a component is required when its code needs to
be modified or recompiled (science gateway or workflow service), or
when a new piece of software has to be installed (infrastructure
only). Modification of an interaction is deemed necessary when the
parameters involved in this interaction are modified.  Extensibility
breaks down in 4 metrics depending on the type of element that has to
be added or replaced:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item New engine type (\texttt{E$_1$}): number of interactions or
  components to modify to integrate a new type of workflow engine in
  the architecture. Workflow engines belong to different types when
  they cannot be invoked using the same interface. Adding a new type
  of workflow engine allows to execute more workflows in the science
  gateway.
\item New engine version (\texttt{E$_2$}): number of interactions or
  components to modify to integrate a new version of a workflow engine
  in the architecture, assuming that another version of the same
  engine type is already available. Different versions of a workflow
  engine share the same interface, i.e. they can be invoked using the
  same software. When this is not the case, the different versions
  have to be considered as different engine types. 
\item New workflow (\texttt{E$_3$}): adding a new workflow is a very
  common operation that does not require modifying software components
  or interactions. We measure the difficulty to integrate a new
  workflow by counting the number of interactions that need to be
  invoked to integrate a new workflow in the architecture, assuming
  that the engine type and version required to execute this workflow
  are already available.
\item New infrastructure (\texttt{E$_4$}): number of interactions or components to
  modify to integrate a new type of infrastructure in the
  architecture. Adding a new infrastructure allows to provide more
  computing or storage power, to access specific types of resources
  (e.g. GPUs, clouds), or to enforce execution policies 
  (e.g. constrain data to remain in a particular network domain).
%\item New science gateway: \todo{Not sure if this makes sense}.
\end{itemize}
The 4 metrics are summed to obtain a global index that measures the
difficulty to extend the architecture.

\emph{Scalability} corresponds to the ability of the architecture to
cope with high workloads. It is measured by counting the potential
scalability issues in the architectures, i.e. the lack of scalability
features. Features are evaluated using a 3-level metric: 0 means that
the feature is very easy to enable, 1 means that it can be implemented
but with some difficulty, and 2 means that the feature could only be
implemented with a nonsensical amount of effort. Four different
features are identified:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Multiple engine instances (\texttt{S$_1$}): possibility to have
  more than 1 engine instance in the architecture. Workflow engines
  may require important amounts of resources when a lot of workflows,
  or large workflows, are executed. At some point, it may be required
  for the science gateway to distribute the load to several
  engines. \texttt{S$_1$}=0 when adding a new engine instance is a
  fully automated process, i.e. the workflow engine only has to be
  started. In this case, elastic engines are possible, i.e. some kind
  of auto-scaling mechanism can be implemented to control the number
  of engine instances in the architecture. \texttt{S$_1$}=1 when
  adding a new engine instance requires some form of manual
  intervention, which prevents easy implementations of elastic
  engines. \texttt{S$_1$}=2 when new engine instances cannot be added.
\item Distributed engines (\texttt{S$_2$}): possibility to distribute
  the execution \emph{of a single workflow} among different engine
  instances. In our scope, this feature focuses on the capabilities of
  the architecture rather than these of the workflow
  engine. \texttt{S$_2$}=0 when distributed engines are possible in
  the architecture and \texttt{S$_2$}=1 when they require specific
  developments in the workflow engine.
\item Task scheduling (\texttt{S$_3$}): task scheduling is a difficult
  issue that depends more on the implementation of specific algorithms
  in the science gateway, workflow engine and infrastructure than on
  the architecture used to integrate the workflow engine in the
  science gateway. Some architectures, however, complexify the task
  scheduling problem by introducing additional software layers or
  create tasks with specific characteristics. \texttt{S$_3$}=0 when
  the architecture does not introduce any additional complexity to the
  scheduling problem and \texttt{S$_3$}=1 otherwise.
\end{itemize}
The 3 metrics are summed to obtain a global measure of the scalability
issues that are present in the architecture.

\emph{Other features} include:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Meta-workflow (\texttt{O$_1$}): ability to describe
  meta-workflows from existing workflows.  \todo{More details about
    why this is important?} \texttt{O$_1$}=0 when the feature is
  available, \texttt{O$_1$}=1 otherwise.
\item Fine-grained debugging (\texttt{O$_2$}): availability of
  fine-grained debugging information about workflow tasks. When
  such information is available, workflow is seen as a white
  box. Fine-grained information about workflow tasks is required to
  properly troubleshoot workflow executions.  \texttt{O$_2$}=0 when
  such information is easy to access, \texttt{O$_2$}=1
  otherwise. \todo{More details about why this is important?}
\end{itemize}
\texttt{O$_1$} and \texttt{O$_2$} are summed to obtain a total number of missing other
features in the architecture.  \todo{Maybe we could revise the
  categories to avoid such a vague ``other features''.}

%"A Formal Approach to Support Interoperability in Scientific
%Meta-workflows" (reviewed for IWSG and JoGC) has a formal model to
%evaluate CGI and FGI.
%"four major approaches for workflow interoperability include a,b,c,d" (see Terstyanzky et al, "Enabli%ng scientific workflow sharing through CGI...", FGCS 2014) -> read this ref.
% http://www.oreilly.com/programming/free/files/software-architecture-patterns.pdf

The different architectures described in
Figure~\ref{fig:architectures} are evaluated along these metrics in
the remainder of this Section.

\subsection{Tight integration}

\paragraph{Integration} This architecture does not require any
component in addition to the science gateway and infrastructure
(\texttt{I$_1$=2}). It involves 5 interactions: \texttt{a$_1$},
\texttt{a$_2$}, \texttt{b}, \texttt{c$_1$} and \texttt{c$_2$}
(\texttt{I$_2$=5}).

\paragraph{Robustness} No component is specific to workflow execution
(\texttt{R$_1$}=0), but interactions \texttt{b} and \texttt{c$_2$} are
(\texttt{R$_2$}=2).

\paragraph{Extensibility} Integrating a new type of workflow engine
requires to modify the science gateway as well as interactions
\texttt{b} and \texttt{c$_2$} (\texttt{E$_1$}=3). Updating a workflow
engine version requires modifications in the science gateway
(\texttt{E$_2$}=1).  Inserting a new workflow is done through
interactions \texttt{a$_1$} and \texttt{a$_2$} (\texttt{E$_3$}=2). Adding a new infrastructure generates updates in
interactions \texttt{b}, \texttt{c$_1$} and \texttt{c$_2$}
(\texttt{E$_4$}=3).

\paragraph{Scalability} Adding a new engine instance requires a new
instance of the science gateway, which is in general not possible
(\texttt{S$_1$}=2). Distributed engines are not available by default
(\texttt{S$_2$}=1). The scheduling of tasks on the infrastructure is
as complex as in any other architecture since the workflow engine
might implement any kind of scheduling policy (\texttt{S$_3$}=0).

\paragraph{Other features} Meta-workflows are not supported by default
(\texttt{O$_1$}=1).  Debugging is not an issue since the science
gateway can retrieve any information from the workflow engine directly
(\texttt{O$_2$}=0).

\subsection{Service invocation} 

\paragraph{Integration} Service invocation requires a workflow service
in addition to the science gateway and infrastructure
(\texttt{I$_1$}=3). The architecture involves 6 interactions:
\texttt{a$_1$}, \texttt{a$_2$}, \texttt{b}, \texttt{c$_1$},
\texttt{c$_2$} and \texttt{d} (\texttt{I$_2$}=6).

\paragraph{Robustness} The workflow service is a component specific to
workflow execution (\texttt{R$_1$}=1). Workflow execution also
involves 3 specific interactions: \texttt{b}, 
\texttt{c$_2$} and \texttt{d} (\texttt{R$_2$}=3).

\paragraph{Extensibility} Adding a new type of workflow engine requires
to implement the corresponding workflow service, to modify interaction
\texttt{d}, and to implement interactions \texttt{b} and
\texttt{$c_2$} (\texttt{E$_1$}=4). New engine versions can be added by
updating the workflow service without modifying any interaction
(\texttt{E$_2$}=0).  New workflows are added in the science gateway or
in the workflow engine through interactions \texttt{a$_1$} and \texttt{a$_2$}
(\texttt{E$_3$}=2). Adding a new type of infrastructure requires
updates in interactions \texttt{b}, \texttt{$c_1$} and \texttt{$c_2$}
(\texttt{E$_4$}=3). 

\paragraph{Scalability} The service architecture supports multiple
engine instances through multiple workflow services. In VIP for
instance, this feature has been available from release 1.17 (April
2016). A basic load-balancing mechanism is available that sends new
workflow executions to the engine instance that has the least active
executions. To avoid ``black-hole'' syndromes created by failing
engine instances, engine instances are automatically disabled when
workflows cannot be submitted to them. Adding a new engine instance,
however, requires manual intervention to declare the new instance in
the science gateway (\texttt{S$_1$}=1). Consequently, elastic engines
are difficult to implement because they require a mechanism to update
the science gateway configuration when a new engine instance is
available. Distributing the execution of a single
workflow in multiple engines is usually not possible unless the
workflow engine has specific abilities (\texttt{S$_2$}=1). The
scheduling of tasks on the infrastructure is as complex as in any
other architecture since the workflow engine might implement any kind
of scheduling policy (\texttt{S$_3$}=0).

\paragraph{Other features} Meta-workflow are not supported by default
(\texttt{O$_1$}=1). Fine-grained debugging information is usually easy
to obtain since the workflow service provides direct access to the
engine (\texttt{O$_2$}=0).

\subsection{Sub-task}

\paragraph{Integration} The sub-task architecture requires only 2
components (\texttt{I$_1$}=2).  It involves 5 interactions:
\texttt{a$_1$}, \texttt{a$_2$}, \texttt{b}, \texttt{c} and
\texttt{e} (\texttt{I$_2$}=5).

\paragraph{Robustness} No component is specific to workflow execution
(\texttt{R$_1$}=0), and only interaction \texttt{e} is
(\texttt{R$_2$}=1).

\paragraph{Extensibility} Integrating a new type of workflow engine
requires to develop interaction \texttt{e} and to install the engine
on the infrastructure (\texttt{E$_1$}=2). Updating an engine version
requires updates only on the infrastructure (\texttt{E$_2$}=1).  New
workflows are integrated by creating a new task in the science gateway
through interactions \texttt{a$_1$} and \texttt{a$_2$}  (\texttt{E$_3$}=2). Adding a new
infrastructure requires to update interactions \texttt{b} and
\texttt{c} in the science gateway (\texttt{E$_4$}=2).

\paragraph{Other features} Meta-workflows are not available
(\texttt{O$_1$}=1).  Obtaining fine-grained information about workflow
tasks is not straightforward since the science gateway has no
knowledge about the workflow topology, and the workflow engine is
integrated as a task (\texttt{O$_2$}=1).

%\todo{Integrating a workflow engine as a sub-task
%only requires to implement interaction \texttt{e} (\texttt{I$_2$}=1)
%and to install the workflow engine on the infrastructure
%(\texttt{I$_3$}=1). A new task type is created in the science gateway
%only when a new workflow has to be integrated (see M$_4$), but this is
%not required to integrate the engine itself (\texttt{I$_1$}=0).}


\paragraph{Scalability}
New engine instances are spawned and executed on the infrastructure as
any other task upon user submission (\texttt{S$_1$}=0). This is a
major interest of the sub-task architecture. Distributed engines are
not supported by default (\texttt{S$_2$}=1). Task scheduling is
slightly more complex than in the other approaches due to the special
role of the task that executes the workflow engine
(\texttt{S$_3$}=1). Indeed, the reliability of this task is critical
since all the sub-tasks in the workflow depend on it and, depending on
the recovery capabilities of the workflow engine, may need to be
resubmitted if the workflow task fails. The workflow task is also
longer than all its sub-tasks, which increases its chances of
failure. In addition, task parameters, for instance estimated
walltime, are more difficult to estimate for the workflow task than
for sub-tasks which may generate issues such as selection of wrong
batch queues on clusters. Finally, the interdependencies between the
workflow task and its sub-tasks may create deadlocks when there is
contention. Say for instance that only 1 computing resource is
available for the science gateway and that the workflow task is
running on it and submits sub-tasks, then the sub-tasks could only
execute when the resource is available, which will never happen
because the workflow task will not complete until the sub-tasks
complete. This configuration can be generalized to an infrastructure
with $n$ resources where $n$ workflows are submitted. In practice,
however, the number of submitted workflows usually remains lower than
the number of computing resources available on this infrastructure,
which makes such deadlocks unlikely to happen.

\subsection{Pool}

\paragraph{Integration} The pool model requires a workflow pool and an
agent in addition to the science gateway and infrastructure
(\texttt{I$_1$=4}). It involves 7 interactions: \texttt{a$_1$},
\texttt{a$_2$}, \texttt{b}, \texttt{c$_1$}, \texttt{c$_2$}, \texttt{d}
and \texttt{f} (\texttt{I$_2$}=7).

\paragraph{Robustness} The workflow pool and agent are specific to
workflow execution (\texttt{R$_1$=2}). Interactions \texttt{b},
\texttt{c$_2$}, \texttt{d} and \texttt{f} also are (\texttt{R$_2$=4}).

\paragraph{Extensibility} Adding a new engine type requires to wrap
the engine in the agent and to update interactions \texttt{b} and
\texttt{c$_2$} (\texttt{E$_1$=3}). Updating the version of an engine
is transparent (\texttt{E$_2$=0}) \todo{explain why, also for service}, and integrating a new workflow is
done through interactions \texttt{a$_1$} and \texttt{a$_2$}
(\texttt{E$_3$=2}). Integrating a new infrastructure requires updates
in interactions \texttt{b}, \texttt{c$_1$} and \texttt{c$_2$}
(\texttt{E$_4$=3}).

\paragraph{Scalability} New engine instances only require new agents,
which is easily automated (\texttt{S$_1$=0}) and by design very
suitable for elastic computing. For instance, auto-scaling rules can
be implemented to start new agents when the workload in the science
gateway exceeds a certain threshold \todo{ref needed}. Distributed
engines are not available by default (\texttt{S$_2$=1}) and task
scheduling is as complex as in any other architecture
(\texttt{S$_3$=0}).

\paragraph{Other features} Meta-workflows are not available by default
(\texttt{O$_1$=1}).  Accessing debugging information is not likely to
be an issue since the workflow pool could implement specific functions
for that (\texttt{O$_2$=0}).

\subsection{Nested workflows with service invocation}

\paragraph{Integration} Setting up a nested workflow architecture with
service invocation requires a science gateway, 2 workflow services and
2 infrastructures (\texttt{I$_1$=5}). The architecture involves 11
interactions (\texttt{I$_2$=11}): \texttt{a$_1$} (twice: once for each
infrastructure), \texttt{a$_2$}, \texttt{b} (twice: once for each
infrastructure), \texttt{c$_1$} (twice: once for each infrastructure),
\texttt{c$_2$} (twice: once for each workflow engine and
infrastructure) and \texttt{d} (twice: once for each workflow engine).

\paragraph{Robustness} The two workflow services are specific to
workflow execution (\texttt{R$_1$=2}). Interactions \texttt{b}
(counted twice), \texttt{c$_2$} (twice) and \texttt{d} (twice) also
are (\texttt{R$_2$=6}).

\paragraph{Extensibility} Adding a new type of \emph{parent} engine
requires to implement the corresponding service, to implement
interactions \texttt{b} and \texttt{c$_2$} in the parent engine, and
to implement interaction \texttt{d} in the science gateway and in the
parent service (\texttt{E$_1$=5}). Adding a new type of \emph{child}
engine only requires to implement the corresponding service, to
develop interactions \texttt{b} and \texttt{c$_2$} in the child
engine, and to implement interaction \texttt{d} in the parent service
(\texttt{E$_1$=4}). We use \texttt{E$_1$=4.5} in
Table~\ref{table:evaluation} to reflect both conditions. Adding a new
version in the parent or child engine only requires modifying this
engine (\texttt{E$_2$=0}). Adding a new
workflow is done through interaction \texttt{a$_1$} and \texttt{a$_2$}
(\texttt{E$_3$=2}). Adding a new infrastructure requires to
re-implement interactions \texttt{b} and \texttt{c$_2$} twice, and
interaction \texttt{c$_1$} once (\texttt{E$_4$=5}). 

\paragraph{Scalability} As in the service architecture, adding a new
workflow instance requires manual configuration in the science gateway
(instance of a parent engine), or in the parent engine (instance of a
child engine) (\texttt{S$_1$=1}). Similarly, elastic engines are
difficult to achieve. Distributed engines are
possible, through meta-workflows (\texttt{S$_2$=0}). Task scheduling
is more complex than in other architectures though, due to the fact
that workflow execution is split in different engines (\texttt{S$_3$=1}).

\paragraph{Other features} 
Meta-workflows are possible, which is one of the main interest of this
architecture (\texttt{O$_1$=0}).  Debugging is difficult because the
science gateway cannot directly access fine-grained information in the
sub-workflow (\texttt{O$_2$=1}).

\subsection{Workflow import with service invocation}

\paragraph{Integration} Workflow import with service invocation
requires the same components as for service invocation
(\texttt{I$_1$}=3). It requires an additional \texttt{g} interaction
for workflow import (\texttt{I$_1$}=7)

\paragraph{Robustness} Since workflow conversion is not involved in
the execution (it is an offline process), metrics are as in the
service architecture (\texttt{R$_1$=1}, \texttt{R$_2$=3}).

\paragraph{Extensibility} Since adding a new type of workflow engine
aims at supporting more workflows, we consider that it only requires
to re-implement interaction \texttt{g} in this architecture  (\texttt{E$_1$=1}). Note,
however, that implementing interaction \texttt{g} can require very
substantial work depending on the complexity of the language used by
the new engine. Based on the same logic, adding a
new engine version only requires modifying interaction \texttt{g}
(\texttt{E$_2$=1}).  Adding a new workflow is done through
interactions \texttt{a$_1$}, \texttt{a$_2$} and \texttt{g} (\texttt{E$_3$=3}). As in the
service architecture, interfacing with a new infrastructure requires
modifications in the workflow service and in interactions \texttt{b}
and \texttt{c$_2$} (\texttt{E$_4$=3}).

\paragraph{Scalability}  Since workflow conversion is not involved in
the execution (it is an offline process), metrics are as in the
service architecture (\texttt{S$_1$=1},
\texttt{S$_2$=1}, \texttt{S$_3$=0}).

\paragraph{Other features} Meta-workflows are available after import,
by connecting workflows in the language used in the science gateway
(\texttt{O$_1$=0}). Debugging information is accessible as in the
service invocation architecture (\texttt{O$_2$=0}).

\begin{table*}
\centering
\begin{tabular}{rcccccc}
                                     & \textbf{Tight}
                                     & \textbf{Service}
                                     & \textbf{Sub-task}
                                     & \textbf{Pool}
                                     & \textbf{Nested}
                                     & \textbf{Import} \\
\multicolumn{7}{c}{\cellcolor[HTML]{EEEEEE}\textbf{Integration effort}}\\
  Total components -- \texttt{I$_1$} & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99E899}3
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99D199}4
                                     & \cellcolor[HTML]{99BB99}5
                                     & \cellcolor[HTML]{99E899}3\\
Total interactions -- \texttt{I$_2$} & \cellcolor[HTML]{99FF99}5
                                     & \cellcolor[HTML]{99F399}6
                                     & \cellcolor[HTML]{99FF99}5
                                     & \cellcolor[HTML]{99E899}7
                                     & \cellcolor[HTML]{99BB99}11
                                     & \cellcolor[HTML]{99E899}7\\
\textbf{Total} (total software pieces) & \cellcolor[HTML]{99FF99}\textbf{7}
                                     & \cellcolor[HTML]{99EF99}\textbf{9}
                                     & \cellcolor[HTML]{99FF99}\textbf{7}
                                     & \cellcolor[HTML]{99E099}\textbf{11}
                                     & \cellcolor[HTML]{99BB99}\textbf{16}
                                     & \cellcolor[HTML]{99E899}\textbf{10}\\
  \multicolumn{7}{c}{\cellcolor[HTML]{EEEEEE}\textbf{Robustness of workflow execution}}\\
Specific components -- \texttt{R$_1$} & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99DD99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}2
                                     & \cellcolor[HTML]{99BB99}2
                                     & \cellcolor[HTML]{99DD99}1\\
  Specific interactions -- \texttt{R$_2$} & \cellcolor[HTML]{99F199}2
                                     & \cellcolor[HTML]{99E399}3
                                     & \cellcolor[HTML]{99FF99}1
                                     & \cellcolor[HTML]{99D699}4
                                     & \cellcolor[HTML]{99BB99}6
                                     & \cellcolor[HTML]{99E399}3\\
  \textbf{Total} (specific software pieces)& \cellcolor[HTML]{99F599}\textbf{2}
                                     & \cellcolor[HTML]{99E199}\textbf{4}
                                     & \cellcolor[HTML]{99FF99}\textbf{1}
                                     & \cellcolor[HTML]{99CE99}\textbf{6}
                                     & \cellcolor[HTML]{99BB99}\textbf{8}
                                     & \cellcolor[HTML]{99E199}\textbf{4}\\
\multicolumn{7}{c}{\cellcolor[HTML]{EEEEEE}\textbf{Extensibility}}\\
  New engine type -- \texttt{E$_1$}  & \cellcolor[HTML]{99D899}3
                                     & \cellcolor[HTML]{99C499}4
                                     & \cellcolor[HTML]{99EB99}2
                                     & \cellcolor[HTML]{99D899}3
                                     & \cellcolor[HTML]{99BB99}4.5
                                     & \cellcolor[HTML]{99FF99}1\\
New engine version -- \texttt{E$_2$} & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}1\\
  New workflow -- \texttt{E$_3$} & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99BB99}3\\
New infrastructure -- \texttt{E$_4$} & \cellcolor[HTML]{99E899}3
                                     & \cellcolor[HTML]{99E899}3
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99E899}3
                                     & \cellcolor[HTML]{99BB99}5
                                     & \cellcolor[HTML]{99E899}3\\
  \textbf{Total} (difficulty to extend) & \cellcolor[HTML]{99E099}\textbf{9}
                                     & \cellcolor[HTML]{99E099}\textbf{9}
                                     & \cellcolor[HTML]{99FF99}\textbf{7}
                                     & \cellcolor[HTML]{99EF99}\textbf{8}
                                     & \cellcolor[HTML]{99BB99}\textbf{11.5}
                                     & \cellcolor[HTML]{99EF99}\textbf{8}\\
\multicolumn{7}{c}{\cellcolor[HTML]{EEEEEE}\textbf{Scalability}}\\
Multiple engine instances -- \texttt{S$_1$}& \cellcolor[HTML]{99BB99}2
                                     & \cellcolor[HTML]{99DD99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99DD99}1
                                     & \cellcolor[HTML]{99DD99}1\\
Distributed engines -- \texttt{S$_2$}& \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}1\\
Task scheduling -- \texttt{S$_3$}    & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0\\
\textbf{Total} (scalability issues)  & \cellcolor[HTML]{99BB99}\textbf{3}
                                     & \cellcolor[HTML]{99DD99}\textbf{2}
                                     & \cellcolor[HTML]{99DD99}\textbf{2}
                                     & \cellcolor[HTML]{99FF99}\textbf{1}
                                     & \cellcolor[HTML]{99DD99}\textbf{2}
                                     & \cellcolor[HTML]{99DD99}\textbf{2}\\
\multicolumn{7}{c}{\cellcolor[HTML]{EEEEEE}\textbf{Other features}}\\
  Meta-workflow  -- \texttt{O$_1$}    & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0\\
  Fine-grained debugging -- \texttt{O$_2$}   & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99BB99}1
                                     & \cellcolor[HTML]{99FF99}0\\
  \textbf{Total} (missing other features) & \cellcolor[HTML]{99DD99}\textbf{1}
                                     & \cellcolor[HTML]{99DD99}\textbf{1}
                                     & \cellcolor[HTML]{99BB99}\textbf{2}
                                     & \cellcolor[HTML]{99DD99}\textbf{1}
                                     & \cellcolor[HTML]{99DD99}\textbf{1}
                                     & \cellcolor[HTML]{99FF99}\textbf{0}\\
\end{tabular}

\caption{Architecture evaluation. Lower values (brighter colors) indicate better performance. On each row, metric values are
  normalized between 0 (best value) and 1 (worst value) to determine the
  color of the corresponding table cell. More precisely, the normalized metric value $m'$ is
  defined as
  $\frac{m-m_{\mathrm{min}}}{m_{\mathrm{min}}-m_{\mathrm{max}}}$ where
  $m$ is the initial metric value, $m_{\mathrm{min}}$/$m_{\mathrm{max}}$
  are the minimal/maximal values among all architectures. The RGB hexadecimal color code of the cell
  is \texttt{\#99XX99}, where X=F-4m'.}
\label{table:evaluation}
\end{table*}



\section{Discussion}

\subsection{Comparison between architectures}

Tight integration and sub-tasking require the least amount of
integration effort, closely followed by service integration and
workflow import (with service invocation). Pool is a bit behind but
still before nested workflows (with service invocation) which requires
more integration than the other architectures. Robustness leads to the
same ordering of architectures, with tight integration and sub-tasking
in the top group, service integration and workflow import (with
service invocation) close behind, pool in a third group, and nested
workflows (with service invocation) at the end. This ordering is
consistent across metrics, and it reflects the global complexity of
the architectures.

Regarding extensibility, most architectures are overall comparable,
except nested workflows (with service invocation) which is
significantly behind. This is explained by the complexity of the
nested workflow architecture, with 2 infrastructures and 2 workflow
services. Sub-tasking and workflow import (with service invocation)
perform a bit better to integrate new engines (\texttt{E$_1$}), which
is interesting given the current profusion of engines with different
characteristics.  However, sub-tasking, workflow import (with service
invocation) and tight integration perform worse than the others to add
engine versions (\texttt{E$_2$}) due to the need to update
infrastructure (sub-tasking), science gateway (tight integration), or
workflow converter (workflow import). Workflow import performs worse
than the others to integrate new workflows (\texttt{E$_3$}) because of
the language conversion step. All architectures except nested
workflows perform the same to integrate new infrastructures (\texttt{E$_4$}).

The pool architecture is overall the most scalable, which is not a
surprise since it was designed precisely for scalability. Tight
integration is the least scalable and all the other architectures
perform the same. The overall scalability score, however, should not
mask the unique characteristics of architectures regarding this
criterion. For instance, nested workflows are the only architecture
that can easily accommodate distributed workflow execution, which can
be critical in some cases. At the same time, the scheduling
constraints created by the sub-tasking and nested workflow
architectures could well become showstoppers depending on the type of
targeted infrastructure. Non-reliable infrastructures, for example,
could hardly cope with workflow engines being wrapped in computing
tasks as done in sub-tasking. The availability of multiple engine
instances could also become a critical feature for science gateways
with important workloads, which would favor sub-tasking and pool.

Differences in other features should not be neglected. Nested
workflows (with service invocation) and workflow import (with service
invocation) are the only architectures that support meta-workflows,
which may be interesting in some cases. The availability of
fine-grained debugging information may also be critical to efficient
user support. 

Table~\ref{table:overall} provides an overall comparison between
architectures, based on the metrics in
Table~\ref{table:evaluation}. While Table~\ref{table:overall} provides
a global comparison between architectures, it should not be used
without the detailed metrics reported on Table~\ref{table:evaluation}
and discussed above. Overall, sub-tasking, and workflow import (with
service invocation) perform a bit better than tight integration,
service invocation and pool. Nested workflows stands a bit behind for
the reasons mentioned previously.
\begin{table*}
\centering
\begin{tabular}{rcccccc}
                                    & \textbf{Tight}
                                    & \textbf{Service}
                                    & \textbf{Sub-task}
                                    & \textbf{Pool}
                                    & \textbf{Nested}
                                    & \textbf{Import} \\
  Integration effort (normalized total) & 
                                    \cellcolor[HTML]{99FF99}{0.00}
                                    & \cellcolor[HTML]{99EF99}{0.22}
                                    & \cellcolor[HTML]{99FF99}{0.00}
                                    & \cellcolor[HTML]{99E099}{0.44}
                                    & \cellcolor[HTML]{99BB99}{1.00}
                                      & \cellcolor[HTML]{99E899}{0.33}\\                           
Robustness (normalized total) & 
                                \cellcolor[HTML]{99F599}{0.14}
                                    & \cellcolor[HTML]{99E199}{0.43}
                                    & \cellcolor[HTML]{99FF99}{0.00}
                                    & \cellcolor[HTML]{99CE99}{0.71}
                                    & \cellcolor[HTML]{99BB99}{1.00}
                                    & \cellcolor[HTML]{99E199}{0.43}\\
  Extensibility (normalized total)  & \cellcolor[HTML]{99E099}{0.44}
                                     & \cellcolor[HTML]{99E099}{0.44}
                                     & \cellcolor[HTML]{99FF99}{0.00}
                                     & \cellcolor[HTML]{99EF99}{0.22}
                                     & \cellcolor[HTML]{99BB99}{1.00}
                                     & \cellcolor[HTML]{99EF99}{0.22}\\
Scalability (normalized total)  & \cellcolor[HTML]{99BB99}{1.00}
                                     & \cellcolor[HTML]{99DD99}{0.50}
                                     & \cellcolor[HTML]{99DD99}{0.50}
                                     & \cellcolor[HTML]{99FF99}{0.00}
                                     & \cellcolor[HTML]{99DD99}{0.50}
                                     & \cellcolor[HTML]{99DD99}{0.50}\\
Other features (normalized total) & \cellcolor[HTML]{99DD99}{0.50}
                                     & \cellcolor[HTML]{99DD99}{0.50}
                                     & \cellcolor[HTML]{99BB99}{1.00}
                                     & \cellcolor[HTML]{99DD99}{0.50}
                                     & \cellcolor[HTML]{99DD99}{0.50}
                                     & \cellcolor[HTML]{99FF99}{0.00}\\
                                    & \cellcolor[HTML]{99EE99}\textbf{2.1}
                                    & \cellcolor[HTML]{99EE99}\textbf{2.1}
                                    & \cellcolor[HTML]{99FE99}\textbf{1.5}
                                    & \cellcolor[HTML]{99F499}\textbf{1.9}
                                    & \cellcolor[HTML]{99BB99}\textbf{4.0}
                                    & \cellcolor[HTML]{99FF99}\textbf{1.5}\\
\end{tabular}
\caption{Overall evaluation. Brighter colors and lower scores indicate better performance. Scores
  are obtained by summing the normalized total scores ($m'$ values) of
  each criterion in Table~\ref{table:evaluation} and the colors are obtained by normalizing these scores
  as done in Table~\ref{table:evaluation}. }
\label{table:overall}
\end{table*}

\subsection{Limitations}

A few limitations remain with our evaluation. First of all, the
evaluation is done at a quite high-level of abstraction that may be a
bit artificial when applied to real systems. Abstracting architectures
from their implementation in specific systems is fundamental to the
progress of software engineering of science gateways, but we also
realize that this comes at the cost of realism. 

In particular, the presented architectures are pure patterns that may
be blended in actual systems. The distinction between tight
integration and service invocation, for instance, may not be that
clear in practice. Service invocation may also be combined with
sub-tasking in some cases.

Moreover, all the interactions involved in the architectures were
treated equally, as if they all required similar amounts of
development effort, which is realistically not the case. For example,
interaction \texttt{g} (workflow language conversion) clearly requires
more effort than interaction \texttt{d} (service invocation), and may
create much more reliability issues as well. However, quantifying the
robustness and amount of development associated with each interaction
and software component cannot realistically be done without entering
into the details of a particular system.

The particular case of interaction \texttt{g} (workflow language
conversion) should be further discussed since it is very likely that
this interaction could not be easily generalized to any workflow
language. For instance, converting FSL, PSOM or Nipype pipelines to
any other workflow language is very tricky because these engines rely
on general-purpose programming languages (bash, Octave, Python, etc)
which are much richer than scientific workflow languages.

The abstract nested workflows and workflow import patterns were
instantiated with service invocation so that they can be analyzed in
the same framework as the other architectures. Other types of
instantiation, for instance nested workflows with sub-tasking, could
also be envisaged. We chose to limit ourselves to instantiations with
service invocation because the resulting architectures are implemented in 
real systems, and because service invocation is a largely
used architecture. Nested workflows with sub-tasking, in particular,
could be an interesting architecture to explore. 

Finally, there is no need to say that the particular technical or
historical context of a science gateway project may influence the
choice of an architecture to integrate workflow engines. For instance,
some workflow engines may be already available as web services, which
would tend to favor service invocation, and other science gateways may
have strongly tested task and data control features (interactions
\texttt{b} and \texttt{c}), which would favor sub-tasking. The
migration cost between architectures is totally ignored as well.

\section{Conclusion}

\todo{Section still to be written}


We abstracted architectures so that we can compare them using
objective metrics. We illustrated these architectural patterns on
examples of real systems.

What this work highlights and recommendations for science gateway
developers.

\section{Acknowledgments}

\todo{Section still to be written}

\todo{FLI-IAM, Labex PRIMES, Ludmer Centre, whatever grant is funding
  POQ for integrating CBRAIN with PSOM.}

We warmly thank Rafael Ferreira da Silva for implementing the VIP
platform and creating Figure~\ref{fig:vip-architecture}.

\section*{References}

\bibliographystyle{elsarticle-num} 
\bibliography{biblio}

\end{document}
\endinput
