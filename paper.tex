\documentclass[preprint,3p,twocolumn]{elsarticle}

\usepackage[x11names,dvipsnames,table]{xcolor} %for use in color links
\usepackage[subrefformat=parens,labelformat=parens]{subfig}
\usepackage{svg}
\usepackage{url}
\usepackage{flushend}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage[bookmarks]{hyperref}
\usepackage{multirow}
\usepackage{pbox}
\usepackage{pdfcomment}
\definecolor{ao(english)}{rgb}{0.0, 0.5, 0.0}
\newcommand{\todo}[2]{\pdfmargincomment[color=red,author=#1,open=true]{#2}}
%\newcommand{\note}[2]{\pdfmargincomment[color=yellow,author=#1,open=true]{#2}}
%\newcommand{\closednote}[4]{} % closed notes are hidden. This should obviously be a parameter of \note rather than a separate command.
%\newcommand{\answerednote}[4]{\pdfmargincomment[color=green,author=#1-#3,open=true]{#1: #2 \textCR \textCR #3: #4}}
%\newcommand{\closedanswerednote}[6]{}
\newcommand{\correction}[1]{\color{blue}#1\color{black}\xspace}

\renewcommand\thesubfigure{\Roman{subfigure}}

\journal{Future Generation Computer Systems}

\begin{document}

\begin{frontmatter}

\title{Software architectures to integrate workflow engines in science gateways} 

\author[concordia,mcgill,creatis]{Tristan Glatard}
\author[mcgill]{Marc-\'Etienne Rousseau}
\author[creatis]{Sorina Camarasu-Pop}

\author[mcgill]{Reza Adalat}
\author[mcgill]{Natacha Beck}
\author[mcgill]{\\Samir Das}
\author[isi]{Rafael Ferreira da Silva}
\author[mcgill]{Najmeh Khalili-Mahani}
\author[stpetersburg]{Vladimir Korkhov}
\author[criugm]{Pierre-Olivier Quirion}
\author[mcgill]{Pierre Rioux}
\author[amc]{S\'ilvia D. Olabarriaga}
\author[criugm]{Pierre Bellec}
\author[mcgill]{Alan C. Evans}

\address[concordia]{Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada.}
\address[mcgill]{McGill Centre for Integrative Neuroscience, Montreal Neurological Institute, McGill University, Canada.}
\address[creatis]{University of Lyon, CNRS, INSERM, CREATIS, Villeurbanne, France.}
\address[criugm]{Centre de Recherche de l'Institut de G\'eriatrie de Montr\'eal CRIUGM, Montr\'eal, QC, Canada.}
\address[isi]{University of Southern California, Information Sciences Institute, Marina del Rey, CA, USA.}
\address[amc]{Dept. Clinical Epidemiology, Biostatistics and Bioinformatics, Academic Medical Center, University of Amsterdam, NL.}
\address[stpetersburg]{St. Petersburg State University, Russia.}

\begin{abstract}
  Science gateways often rely on workflow engines to execute
  applications on distributed infrastructures. We investigate six
  software architectures commonly used to integrate workflow engines
  into science gateways. In \emph{tight integration}, the workflow
  engine shares software components with the science gateway. In
  \emph{service invocation}, the engine is isolated and invoked
  through a specific software interface. In \emph{task encapsulation},
  the engine is wrapped as a computing task executed on the
  infrastructure. In the \emph{pool model}, the engine is bundled in
  an agent that connects to a central pool to fetch and execute
  workflows. In \emph{nested workflows}, the engine is integrated as a
  child process of another engine. In \emph{workflow conversion}, the
  engine is integrated through workflow language conversion. We
  describe and evaluate these architectures with metrics for
  assessment of integration complexity, robustness, extensibility,
  scalability and \correction{functionality}. Tight integration and
  task encapsulation are the easiest to integrate and the most
  robust. Extensibility is equivalent in most architectures. The pool
  model is the most scalable one and meta-workflows are only available
  in nested workflows and workflow conversion. These results provide
  insights for science gateway architects and developers.
\end{abstract}

\begin{keyword}
Workflow engines \sep science gateways \sep software architectures.
\end{keyword}

\end{frontmatter}

%\maketitle

\section{Introduction}

Several software architectures can be adopted to integrate workflow
engines in \correction{the ecosystem of tools and services offered by}
science gateways, with important consequences for the development
effort required and resulting system.

This paper describes, \correction{illustrates} and compares such
architectures, based on system-independent representations of their
main components and interactions. It is informed by our experience in
the development and sustained operation of the CBRAIN~\cite{SHER-14},
NSG~\cite{shahand2015data,shahand:2012jgc} and VIP~\cite{GLAT-13}
science gateways during the past 7 years, as well as by lessons
learned from several science gateway and workflow projects such as
SHIWA\footnote{\url{http://www.shiwa-workflow.eu}} and
ER-flow\footnote{\url{http://www.erflow.eu}}.

\correction{This analysis is intended for experts of science gateway
  and workflow engine design. It is an abstraction effort to identify
  and evaluate the fundamental architectural patterns that are
  encountered while integrating workflow engines and science gateways.
  In real systems, such patterns sometimes coexist due to the
  historical and technical context of software projects.}

\correction{The remainder of this section provides} background
information and definitions of workflow engines, science gateways and
infrastructures. In Section~\ref{sec:architectures}, we describe six
architectures within a consistent framework that underlines the
functional interactions between their main software
components. \correction{We illustrate these architectures on real
  systems in Section~\ref{sec:real systems}.} In
  Section~\ref{sec:metrics}, we introduce metrics that measure
  integration complexity, robustness, extensibility, scalability and
  \correction{functionality}. The metrics are specifically designed to
  measure the ability of the architectures to address workflow-related
  issues commonly encountered in science gateways. \correction{We
    evaluate the architectures individually in
    Section~\ref{sec:evaluation}, and we compare and discuss them in
    Section~\ref{sec:discussion}.} \correction{Finally, in
    Section~\ref{sec:application}, we illustrate how our evaluation
    framework can be used to help design new systems. Related work is
    presented in Section~\ref{sec:related}.}

\subsection{Workflow engines}

\label{sec:introduction-engines}
In the last decade, the e-Science community has developed workflow
systems to help application developers access distributed
infrastructures such as clusters, grids, clouds and web
services. These efforts resulted in tools among which
Askalon~\cite{fahringer2005askalon},
Hyperflow~\cite{balis2016hyperflow}, MOTEUR~\cite{GLAT-08i},
Pegasus~\cite{deelman2005pegasus,Deelman201517},
Swift~\cite{zhao2007swift}, Taverna~\cite{oinn2004taverna},
Triana~\cite{taylor2007triana}, VisTrails~\cite{callahan2006managing},
WS-PGRADE~\cite{Kacsuk2012} and
WS-VLAM~\cite{wsvlam}.  Such workflow engines usually describe
applications using a high-level language with specific data and control
flow constructs, parallelization operators, visual edition tools,
links with domain-specific application repositories, provenance
recording and other features. An overview of workflow system
capabilities is available in~\cite{deelman2009workflows}.

At the same time, toolboxes have been emerging in various scientific
domains to facilitate the assembly of software components in
consistent ``pipelines''. In neuroimaging, our primary domain of
interest, tools such as Nipype (Neuroimaging in Python, Pipelines and
Interfaces~\cite{gorgolewski2011nipype}), PSOM (Pipeline System for
Octave and Matlab~\cite{bellec2012pipeline}), 
PMP (Poor Man's Pipeline~\cite{Ad-DabbaghY2006}), RPPL~\cite{1174106}, SPM (Statistical
Parametric Mapping~\cite{ashburner2011spm}) and FSL (FMRIB Software
Library~\cite{Jenkinson2012782}) provide abstractions and functions to
handle the data and computing flow between processes implemented in a
variety of programming languages. Such tools were interfaced to
computing infrastructures, in particular
clusters, to execute tasks at a high throughput. Some of
these tools also support advanced features such as provenance
tracking or  redundancy detection across
analyses to avoid re-computation. A wide array of workflows
have been implemented using these pipeline systems and are now shared across
neuroimaging groups world-wide, which represents a tremendous
opportunity for science gateways to leverage. Domain-specific engines
nicely complement e-Science systems that are more oriented towards the
exploitation of distributed computing infrastructures, in particular
grids and clouds.

In this paper, a
\emph{workflow engine} (also abbreviated \emph{engine}) is a piece of
software that coordinates and submits interdependent computing \emph{tasks} to an
\emph{infrastructure} (local server, cluster, grid or cloud) based on
a workflow description (a.k.a \emph{workflow}), using input data
that may consist of files, database entries or simple parameter
values. Although simplistic, this definition covers both e-Science workflow engines and
domain-specific pipeline systems.
Some workflow engines, 
usually from the e-Science community, 
may transfer data across the infrastructure, and others, usually
domain-specific ones, may leave this role to external processes. Workflows
may be expressed in any language, including high-level XML or JSON
dialects such as Scufl or Hyperflow, and low-level scripting languages
such as Bash.

\subsection{Science gateways}

\label{sec:intro_sg}

Science gateways are used to share resources within a community and to
provide increased performance and capacity through facilitated access
to storage and computing power. They are often accessible through a
web interface that helps users manage access rights, data transfers,
task execution, and authentication on multiple computing and storage
locations. Workflow engines are part of this ecosystem as core
components to implement and execute
applications. 

Various science gateways have been developed, including frameworks
such as Apache Airavata~\cite{marru2011apache}, the Catania Science
Gateway Framework~\cite{ardizzone2012decide} and
WS-PGRADE/gUSE~\cite{Kacsuk2012}. Numerous science gateways were built
using such frameworks~\cite{kacsuk2014science,ardizzone2012decide} or
as standalone systems~\cite{SHER-14,GLAT-13}. Most of these systems
include one or several workflow engines.

Integration between workflow engines and science gateways varies
across systems. Some science gateways are tailored to a particular
engine, while others are more general and host applications
executed by different types of engines. %Some gateways may not even use any
%workflow engine and focus on the execution of simple tasks.

Extensibility is an important property of the integration. New
workflows are added frequently, different types and versions of
workflow engines may be integrated over time, and different kinds of
infrastructure can be targeted. 

Scalability is also a crucial concern for such multi-user,
high-throughput systems. For this purpose, science gateways may
balance the load among different instances of the same engine, start
new engines elastically using auto-scaling techniques such as the ones
reviewed in~\cite{lorido2012auto}, and use advanced task scheduling
policies on the infrastructure to improve performance, fault-tolerance
and fairness among users.

Robustness is highly desirable as well since it is key to a
good user experience. Simple architectures facilitate the
implementation effort towards robust interactions which, in turn, have
a positive impact on characteristics such as gateway predictability,
transparency, reliability, traceability and
reproducibility. 

Other specific features may also be available, for instance
data vizualisation and quality control, workflow edition, debugging
instruments, or social tools among users. 

\subsection{Infrastructure}

An infrastructure consists of the computing and storage
resources involved in workflow execution, as well as the software
services used to access these resources. The infrastructure can be
composed of computing or file servers, databases, clusters, grids or
clouds. Some workflow engines and science gateways may require specific
characteristics, such as the presence of a shared file system between
the computing nodes, the availability of a global task meta-scheduler, or
the presence of a file catalog. In the analysis presented hereafter,
such specific requirements are not discussed. Instead, we consider the
infrastructure as an abstract system that can execute tasks and store
data regardless of the enabling mechanisms.

\section{Architectures}
\label{sec:architectures}


Architectures to integrate workflow engines in science gateways are
presented in Figure~\ref{fig:architectures} using the graphical
notations defined in Figure~\ref{fig:notations}. \correction{Software
  components are defined at a granularity such that two components may
  potentially be operated by different teams on different hardware
  systems. For instance, the science gateway and infrastructure are
  usually distinct components. In real systems, software components
  may exist at a finer granularity, to implement functions such as
  authentication, data persistence or logging. Such fine-grained
  components are not covered by our analysis since we focus on the
  interactions between the science gateway, the infrastructure and the
  workflow engine.}  Table~\ref{table:system-classification}
summarizes the classification of a few systems by architecture.

%http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4782949

\begin{figure}
\centering
\def\svgwidth{0.8\columnwidth}
\input{figures/notations.pdf_tex}
\caption{Graphical notations}
\label{fig:notations}
\end{figure}

\begin{figure*}
\centering
\hspace*{0.2\columnwidth}
\subfloat[Tight integration]{
\def\svgwidth{0.6\columnwidth}
\input{figures/tight.pdf_tex}
\label{archi:tight}
}
\hfill
\subfloat[Service invocation]{
\def\svgwidth{0.6\columnwidth}
\input{figures/service.pdf_tex}
\label{archi:service}
\hspace*{0.2\columnwidth}
}\\
\hspace*{0.2\columnwidth}
\subfloat[Task encapsulation]{
\def\svgwidth{0.6\columnwidth}
\input{figures/sub-task.pdf_tex}
\label{archi:sub-task}
}
\hfill
\subfloat[Pool]{
\def\svgwidth{0.6\columnwidth}
\input{figures/agent.pdf_tex}
\label{archi:agent}
\hspace*{0.2\columnwidth}
}\\
\subfloat[Nested workflows. Left: abstract model. Right: instantiation with service invocation (``Service+Service'').]{
\def\svgwidth{0.9\columnwidth}
\input{figures/nested-1.pdf_tex}
\def\svgwidth{0.9\columnwidth}
\input{figures/nested-2.pdf_tex}
\label{archi:nested}
}\\
\subfloat[Workflow conversion. Left: abstract model. Right: instantiation with service invocation.]{
\def\svgwidth{0.5\columnwidth}
\input{figures/import-1.pdf_tex}
\hfill
\def\svgwidth{0.5\columnwidth}
\input{figures/import-2.pdf_tex}
\label{archi:import}
}
\caption{Architectures}
\label{fig:architectures}
\end{figure*}
\begin{table*}
\centering
\footnotesize
\rowcolors{1}{white}{gray!25}
\begin{tabular}{ll}
  \textbf{Architecture} & \textbf{Systems} \\
  \hline
  Tight & \pbox{1.5\columnwidth}{
          \correction{Gateways based on the} Catania Science Gateway Framework~\cite{ardizzone2012decide},
          Distributed application runtime environment (DARE~\cite{maddineni2012distributed}),
          LONI Pipeline Environment~\cite{dinov2009efficient}
          }
  \\
  Service & \pbox{1.5\columnwidth}{
             \correction{Gateways based on} Apache Airvata~\cite{marru2011apache}, HubZero with Pegasus~\cite{CPE:CPE3257}, System in~\cite{wu2010accelerating}, Vine Toolkit~\cite{DBLP:journals/scpe/SzejnfeldDKKKKLPTWDNW10}, Virtual Imaging Platform~\cite{GLAT-13},           \correction{Gateways based on the} WS-PGRADE/gUSE framework~\cite{Kacsuk2012}, GridSFEA~\cite{Elts2010}
            } \\
  Task & CBRAIN and PSOM~\cite{GLAT-16}, CBRAIN and FSL\\
  Pool & SHIWA pool~\cite{ROGE-13}\\
  Nested & \pbox{1.5\columnwidth}{SHIWA Simulation Platform (Coarse-Grained Interoperability~\cite{terstyanszky2014enabling}), HubZero with Pegasus (via hierarchical workflows)~\cite{Deelman201517}, Tavaxy~\cite{Abouelhoda2012}.
           }\\
  Conversion & SHIWA Simulation Platform (Fine-Grained Interoperability)~\cite{plankensteiner-prodan-etal:2013}, Tavaxy~\cite{Abouelhoda2012}, system in~\cite{delaGarza2016}.
\end{tabular}
\caption{Classification of science gateways based on the architecture used to integrate workflow engines.}
\label{table:system-classification}
\end{table*}

\subsection{Interactions}

The interactions involved in the architectures are described below and
labeled from \texttt{a} to \texttt{g} as in Figure~\ref{fig:architectures}.

\begin{enumerate}[leftmargin=0cm,itemindent=0.65cm,label=\texttt{(\alph*)}]

\item Workflow integration: consists in adding a new workflow to the
  system so that users can execute it. It is triggered by an
  administrator of the science gateway and it results in an interface,
  for instance a web form, where users can enter the parameters of the
  workflow to be executed. The interaction has two steps:
  (\texttt{a$_1$}) the programs used in the workflow are installed on
  the infrastructure or prepared for on-the-fly deployment, which
  may require specific privileges; (\texttt{a$_2$}) the
  workflow is configured in the science gateway so that it becomes
  available to users. Note that integrating a workflow is not the same
  process as integrating a workflow \emph{engine}.
\item Task control: operations to manage tasks on the infrastructure,
  including authentication, submission, monitoring, termination,
  deletion, etc. Controlling tasks requires dealing with the
  heterogeneous batch managers and meta-schedulers that might be
  available on the infrastructure. When the infrastructure is a grid
  or a cloud, control may be achieved for instance using libraries that
  implement standards such as SAGA (Simple API for Grid
  Applications~\cite{goodale2006saga}), DRMAA (Distributed Resource
  Management Application API~\cite{troger2012distributed}), or OCCI
  (Open Cloud Computing Interface~\cite{edmonds2012toward}).
\item Data control: operations to manage data on the infrastructure,
  such as upload, download, deletion, browsing, replication, caching,
  etc. Data movements can be triggered \correction{by} the science
  gateway (\texttt{$c_1$}), \correction{e.g.,} to upload input data or
  download processed data. They can also be performed by the workflow
  engine (\texttt{$c_2$}), to transfer workflow data (inputs, outputs,
  or intermediate results) across the infrastructure so that tasks can
  use them. The infrastructure might offer various data storage
  backends with heterogeneous interfaces.  Tools and services such as
  JSAGA~\cite{reynaud2010uniform} or Data Avenue~\cite{hajnal2014data}
  can be used to homogenize these interfaces.
\item Workflow control: operations to control workflow execution in an
  engine, including workflow submission, monitoring, termination,
  etc. Workflow control can be coarse-grained (black box) or
  fine-grained (white box). In a coarse-grained model, the various
  tasks created by a workflow execution are masked and the user only
  has a global view of the workflow execution. In a fine-grained
  model, user is exposed to the workflow topology, i.e., to the outputs
  of the individual tasks, their statuses, dependencies and so on.
\item Sub-task control: operations used by tasks to submit sub-tasks
  on the infrastructure, including: submission, monitoring,
  termination, deletion, etc. Sub-task control is similar to
  interaction \texttt{b}, except that information about the parent
  of a sub-task is usually available and used for
  additional control. For instance, the parent task may wait for all
  its sub-tasks to complete before finishing, and conversely all the
  sub-tasks may be terminated if the parent task is killed.
\item Pool-agent: specific to the pool architecture. This is an
  interaction used when agents retrieve work from a central pool. It
  covers agent registration and de-registration to the pool, protocols
  to send work from the pool to the agent, mechanisms to update work
  status, and so on. A similar type of interaction is used in
  pilot-job systems~\cite{turilli2015comprehensive} and other
  agent-based computing models.
\item Workflow conversion: translation from one workflow language into
  another. This interaction may not be available or possible for every
  workflow language. It has been developed mostly for translation
  between well-structured and relatively simple workflow languages
  such as GWorkflowDL and Scufl~\cite{OLAB-09}, and for translation
  among the 5 workflow systems in the SHIWA project: Askalon, MOTEUR,
  Taverna, Triana and WS-PGRADE.  
\end{enumerate}


\subsection{Tight integration}

See Figure~\subref*{archi:tight}. The workflow engine is tightly
integrated with the science gateway, which means that it is deployed
on the same machine and potentially shares code, libraries and other
software components with the science gateway. For instance, the
workflow engine might be a portlet in a Liferay portal or a model in a
Ruby on Rails application\footnote{\correction{Note that the
    particular case of portlets can be a bit ambiguous: when portlets
    are deployed remotely, using protocols such as Web Services for
    Remote Portlets (WSRP), they become independent software
    components according to our definition because they could be
    operated by different teams on different hardware systems. In this
    case, the system should be classified in the service invocation
    architecture since the portlets actually become Web Services. The
    same comment holds for remote object invocation.}}. The workflow
engine and the science gateway usually share a database where
applications, users and other resources are stored.  In this model,
task and data control are both initiated from the science
gateway. Interactions \texttt{b} and \texttt{c$_2$} are initiated from
the workflow engine, while \texttt{c$_1$} comes from other parts of
the science gateway, for instance a data management interface. As in
any other model, the installation of new workflows in the science
gateway (\texttt{a$_2$}) and infrastructure (\texttt{a$_1$}) is done
by an administrator, for security reasons. \correction{Tight
  integration} is the model adopted in the Catania Science Gateway
Framework~\cite{ardizzone2012decide} (see specific documentation on
workflows\footnote{\url{https://frama.link/jfzgaEbj}}), in the
Distributed application runtime environment
(DARE)~\cite{maddineni2012distributed}, in
Galaxy~\cite{goecks2010galaxy}, and in the LONI Pipeline
Environment~\cite{dinov2009efficient}. Note that tightly integrated
architectures may provide advanced workflow edition features which are
not covered by our analysis.
%The Catania Science Gateway Framework would be a good illustration here (workflow engine is a Java portlet), but I can't find a suitable figure about it.
%CIPRES~\cite{miller2010creating} (on which the Neuroscience gateway
%described in~\cite{sivagnanam2015early} is based) % \note{Tristan}{There is no workflow engine in there.}

\subsection{Service invocation}

See Figure~\subref*{archi:service}. The workflow engine is available
externally to the science gateway, as a service. The science gateway
controls the service through a specific interaction (\texttt{d}) that
might be implemented as a web-service call (e.g., RESTful or SOAP), as
a command-line or as any other method that offers a well-defined
interface to the workflow engine. The workflow engine might be invoked
either as a black box that completely masks the infrastructure and
tasks, or as a white box that allows for some interaction with
them. The workflow engine is responsible for controlling the tasks on
the infrastructure (\texttt{b}) and for performing the required data
transfers to execute them (\texttt{c$_2$}). User data is usually
managed through the science gateway (\texttt{c$_1$}), although in some
variations of the architecture (not represented in
Figure~\ref{fig:architectures}) it might as well be delivered by the
workflow engine directly to the user. 

This architecture is largely adopted in systems such as
\correction{the} Apache Airvata
\correction{framework}~\cite{marru2011apache},
GridSFEA~\cite{Elts2010}, Vine
Toolkit~\cite{DBLP:journals/scpe/SzejnfeldDKKKKLPTWDNW10}, Virtual
Imaging Platform~\cite{GLAT-13}, the systems
in~\cite{wu2010accelerating,shahand:2012jgc} and the WS-PGRADE/gUSE
framework~\cite{Kacsuk2012}. The integration between the HubZero
science gateway and the Pegasus workflow engine performed
in~\cite{CPE:CPE3257} also uses a service architecture, where the
\texttt{d} interaction is implemented as a set of calls to Pegasus'
command-line tools (e.g., pegasus-status, pegasus-plan, etc.).

\subsection{Task encapsulation}

See Figure~\subref*{archi:sub-task}. The workflow engine is wrapped in
a particular task that can submit sub-tasks to the science gateway
through interaction \texttt{e}. The workflow engine keeps track of the
dependencies between the sub-tasks, but their execution is delegated
to the science gateway that executes them on the infrastructure
through interaction \texttt{b}. Although the science gateway has no
global vision of the workflow, it \correction{submits the sub-tasks to the
infrastructure} and completely \correction{controls them}. \correction{For instance, it may cancel} them when the
\correction{workflow} is canceled. The science gateway may also
implement mechanisms to facilitate the handling of task dependencies,
for instance \correction{lists of tasks that must be completed before
  a particular task can be executed}.

The science gateway also transfers both user and workflow data across
the infrastructure, through interaction \texttt{c$_1$}.
\subsection{Pool model}
\label{sec:pool}
See Figure~\subref*{archi:agent}. Workflows are submitted by the
science gateway to a central pool through interaction
\texttt{d}. Agents connect to the pool asynchronously to retrieve and
execute workflows through interaction \texttt{f}. Agents may be
started according to various policies, for instance to ensure load
balancing. Workflow engine controls tasks and data on the
infrastructure through interactions \texttt{b} and \texttt{c$_2$},
science gateway transfers user data through interaction
\texttt{c$_1$}, and administrator installs workflows through
interaction \texttt{a$_1$} and \texttt{a$_2$}.

\subsection{Nested workflows}

See Figure~\subref*{archi:nested}. In nested workflows
(Figure~\subref*{archi:nested}-Left), a workflow engine is integrated
as a \emph{child} process of a \emph{parent} workflow engine. Parent
and child engines might use different languages and might run on
different infrastructures. A parent workflow is also a
meta-workflow. The science gateway communicates with the parent engine
through abstract interaction \texttt{*$_1$}. The science gateway also
communicates with the infrastructure to transfer user data through
abstract interactions \texttt{*$_2$} and \texttt{*$_3$}. Both workflow
engines communicate with the infrastructure through abstract
interactions \texttt{*$_4$} and \texttt{*$_5$}. The parent engine
communicates with the child engine through abstract interaction
\texttt{*$_6$}. Administrator installs workflows through interactions
\texttt{a$_1$} and \texttt{a$_2$}.

Nested workflows are abstract architectural patterns that can be
instantiated in the various architectures described previously. We
focus on instantiation with the service invocation model
(Figure~\subref*{archi:nested}-Right) as this is the most used
architecture. \correction{We call this instantiation
  ``Service+Service'' since both engines are integrated through
  service invocation.} We assume that the parent
and child workflow engines are distinct pieces of software that
require different workflow services invoked by distinct \texttt{d}
interactions. If this is not the case, then workflow services can be
collapsed into a single one with a \texttt{d} interaction with
itself. An example of such interaction is the use of hierarchical
workflows in Pegasus~\cite{Deelman201517}.  Workflow engines
communicate with infrastructures using \texttt{b} and
\texttt{c$_2$}. Science gateway transfers user data to infrastructures
using \texttt{c$_1$}.


Nested workflows have long been available in workflow engines, for
instance in the Taverna workbench~\cite{oinn2004taverna}. They are
also used implicitly in several platforms where workflow engines are
wrapped in workflow tasks as any other command-line tool. Nested
workflows were notably used by the SHIWA Science Gateway to implement
so-called Coarse-Grained workflow
interoperability~\cite{terstyanszky2014enabling}, i.e., to integrate
various workflow engines in a consistent
platform. 

\subsection{Workflow conversion}

See Figure~\subref*{archi:import}. This is an abstract model
instantiated with the service invocation architecture for
consistency. \correction{Workflow conversion is presented here as a pattern to
integrate workflow \emph{engines} in a science gateway, through
workflow format conversion from a native format to the science gateway
format.} Workflow conversion is usually an offline process that is not
involved in workflow execution. A few systems have implemented
workflow conversion. In the SHIWA Simulation Platform, it is
implemented through the IWIR language, which provides a common
language for portability across grid workflow
systems~\cite{plankensteiner-prodan-etal:2013} and allows conversion
among $n$ workflow languages using $2n$ interactions instead of $n^2$.
Tavaxy~\cite{Abouelhoda2012} enables the import, merging and execution
of Taverna~\cite{oinn2004taverna} and Galaxy~\cite{goecks2010galaxy}
workflows; when some workflow parts cannot be imported, workflows are
run by Tavaxy as nested workflows using their native engine. The work
in~\cite{delaGarza2016} describes workflow conversion from
KNIME~\cite{Berthold2008} to WS-PGRADE/gUSE and from
Galaxy~\cite{goecks2010galaxy} to WS-PGRADE/gUSE.

%Furthermore, both systems provide web-portals allowing users to share and publish their workflows: These are the myExperiment portal for Taverna [23, 24] and the Public Pages for Galaxy [13].

\correction{\section{Real systems}}

\label{sec:real systems}

\correction{This section illustrates the architectural patterns on a
  few real systems, using the original architecture diagrams published
  by the system developers. To improve readability, we annotated these
  diagrams with the interactions and components used in
  Figure~\ref{fig:architectures}.

\subsection{Tight integration}

The architecture of the Catania Science Gateway Framework (CSGF) is
shown in Figure~\ref{fig:csgf}. In CSGF, workflows are integrated as
Liferay portlets, i.e., as part of the science gateway when no
specific protocol is used for remote invocation. A specific portlet
called \texttt{mi-parallel-portlet} allows to create job collections,
parametric jobs and split-and-merge types of workflows. The science
gateway also includes a set of services to manage data and tasks
(jobs) on a wide array of grid middleware systems through the SAGA
API.
\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figures/CSGF}
\caption{\correction{Architecture of the Catania Science Gateway Framework (tight
  integration). Figure adapted from~\cite{ardizzone2012decide} with
  permission of the first author}.}
\label{fig:csgf}
\end{figure}

\subsection{Service invocation}

Figure~\ref{fig:vip-architecture} shows the architecture of the
Virtual Imaging Platform (VIP), where the MOTEUR workflow
engine~\cite{GLAT-08i} is invoked through a service. The interactions
in the VIP architecture map to the ones defined by our framework in a
straightforward manner, except for interaction \texttt{c$_2$}
(management of workflow data) which, in VIP, is triggered by the
workflow tasks instead of the workflow engine. This does not
contradict the service invocation architecture since the tasks are
generated by the workflow engine.
\begin{figure*}
%\def\svgwidth{1.5\columnwidth}
\includegraphics[width=0.9\textwidth]{figures/VIP.eps}
\caption{\correction{Architecture of the Virtual Imaging Platform (service
  invocation).  Step \texttt{3} corresponds to interaction \texttt{d}
  in Figure~\ref{fig:architectures}(II), step \texttt{2} corresponds
  to interaction \texttt{c$_1$}, step \texttt{4} maps to interaction
  \texttt{b}, and steps 7 and 9 map to \texttt{c$_2$} (in VIP,
  workflow data transfers are performed by the tasks and embedded in
  their descriptions).}}
\label{fig:vip-architecture}
\end{figure*}

\subsection{Task encapsulation}

Task encapsulation is used in the CBRAIN gateway~\cite{SHER-14} to
integrate the FSL toolkit~\cite{Jenkinson2012782} and the PSOM
workflow engine~\cite{bellec2012pipeline}. The CBRAIN-FSL integration,
shown in Figure~\subref*{fig:cbrain-fsl-architecture}, allows
leveraging FSL pipelines written in low-level workflow languages
(Linux executables and scripts) that submit tasks uniformly through a
specific tool called fsl\_sub. The science gateway is actually split
in two services, the CBRAIN portal and the CBRAIN execution server
deployed on a head node of the infrastructure. The mapping of
interactions \texttt{b}, \texttt{c$_1$} and \texttt{e} to the
CBRAIN-FSL interactions is straightforward.

The CBRAIN-PSOM integration~\cite{GLAT-16} is shown in
Figure~\subref*{fig:cbrain-psom-architecture}. The PSOM workflow engine
adopts a pilot-job architecture~\cite{turilli2015comprehensive} where
a master coordinates workflow execution by submitting workers and
establishing direct communication channels with them. Note how this
peculiar execution model is well supported by task encapsulation.

\begin{figure*}
\centering
\subfloat[CBRAIN-FSL integration.]{
\includegraphics[width=\columnwidth]{figures/CBRAIN-FSL.eps}
\label{fig:cbrain-fsl-architecture}
} \hfill \subfloat[CBRAIN-PSOM integration. Figure
adapted from~\cite{GLAT-16}.]{
  \includegraphics[width=\columnwidth]{figures/CBRAIN-PSOM.eps}
\label{fig:cbrain-psom-architecture}
}
\caption{\correction{CBRAIN architecture for workflow engine integration
  (task encapsulation).  1: User sends data and workflow execution request to
  storage server(s) and CBRAIN portal. 2: CBRAIN portal sends
  execution request to execution server on cluster. 3: Execution
  server transfers data from storage server(s). 4-5: Execution server
  starts workflow engine (FSL tool or PSOM master) via task
  scheduler. 6: Workflow engine submits sub-tasks to execution server
  (FSL tasks or PSOM agents). 7-8: Execution server starts sub-tasks
  through task scheduler (FSL sub-tasks or PSOM workers). FSL sub-tasks will run locally
  instead of being submitted again to CBRAIN through interaction 6. 8':
  (PSOM only) PSOM master and workers execute workflow. 9. Execution
  server transfers results to storage server(s). Interaction
  \texttt{b} in Figure~\ref{fig:architectures}(III) is implemented by steps
  \texttt{4}, \texttt{5}, \texttt{7} and \texttt{8} (regular
  interactions with batch manager). Interaction \texttt{$c_1$} is
  implemented by steps \texttt{3} and \texttt{9}. Interaction
  \texttt{e} is implemented by step \texttt{6} (for FSL: through a
  modified version of the fsl\_sub script available in
  \url{https://github.com/aces/cbrain-plugins-neuro}; for PSOM:
  through a specific development in PSOM).}}
\label{fig:cbrain-sub-tasking}
\end{figure*}

\subsection{Pool model}

The pool model was implemented in the SHIWA pool~\cite{ROGE-13}
diagrammed in Figure~\ref{fig:shiwa-pool-architecture}, where agents
can wrap different types of workflow engines to execute workflows
expressed with different languages. The software components map
directly to the ones in our architecture, except that the
infrastructure is not represented. The interactions described in the
SHIWA pool are much finer-grained than in our model, but they can be
grouped to match interactions \texttt{d} and \texttt{f}, as explained
in the Figure caption.

\begin{figure*}
\centering
\includegraphics[width=1.5\columnwidth]{figures/pool-interactions.pdf}
\caption{\correction{Architecture of the SHIWA pool. Circle-terminated arrows
  indicate messages that are broadcast to all pool
  clients. Interaction \texttt{d} of Figure~\ref{fig:architectures}(IV) is
  implemented by 3 different calls to the pool: workflow
  submission (\texttt{1} \& \texttt{2}), workflow status retrieval
  (\texttt{0} \& \texttt{3}), and workflow
  retrieval (\texttt{13} \& \texttt{14}). Interaction
  \texttt{f} is implemented through 2 types of calls: workflow
  instance retrieval (\texttt{4}, \texttt{5} and \texttt{6}), and
  workflow instance update (\texttt{11} and \texttt{12}). Workflow
  instance retrieval is used by the agents to fetch work from the
  pool. Workflow instance update is used by the agents to update
  workflow statuses.  Calls \texttt{0}, \texttt{7}, \texttt{8} and
  \texttt{9} are used by
  workflow engine plugins to declare their supported language and to
  launch engines, and by workflow engines to report their status to
  the agent. These calls are specific to the SHIWA Pool implementation
  of the \texttt{agent} component and therefore have no corresponding
  representation in Figure~\ref{fig:architectures}(IV). Figure adapted
  from~\cite{ROGE-13}.}}
\label{fig:shiwa-pool-architecture}
\end{figure*}

\subsection{Nested workflows with service invocation}

Figure~\ref{fig:shiwa-architecture} shows the architecture used in the
SHIWA Simulation Platform for nested workflow execution with service
invocation. The parent workflow engine is \texttt{WS-PGRADE/gUSE},
invoked as a service in the Science Gateway (interaction
\texttt{d}). Ten different child engines can be used by nested
workflows, invoked through the \texttt{Submission service}
(interaction \texttt{d}). Each of these engines can submit tasks and
transfer data to a distributed computing infrastructure (\texttt{DCI}
interactions \texttt{b} and \texttt{c$_2$}). User data interactions
(\texttt{c$_1$}) and interactions between the parent engine and the
infrastructure (\texttt{b} and \texttt{c$_2$}) are not represented.
\begin{figure*}
\centering
\includegraphics[width=1.5\columnwidth]{figures/shiwa-science-gateway.png}
\caption{\correction{Nested workflow execution through the SHIWA Science Gateway. Figure
  adapted from~\cite{terstyanszky2014enabling} with permission of
  the first author.}}
\label{fig:shiwa-architecture}
\end{figure*}


\subsection{Workflow conversion with service invocation}

Figure~\ref{fig:tavaxy} shows the architecture of Tavaxy where
workflows in various formats (tSCUFL, SCUFL, t2flow and JSON) can be
imported. As detailed in~\cite{Abouelhoda2012}, workflow conversion
(interaction \texttt{g}) is implemented through an interactive
authoring module where users can check and edit workflow imports, and
a mapper module that performs some language substitutions. The
workflow engine is a re-engineered version of the Galaxy engine that
also includes some components of Taverna.
\begin{figure}
\centering
\includegraphics[width=\columnwidth]{figures/Tavaxy.eps}
\caption{\correction{Architecture of Tavaxy (workflow conversion). Figure adapted
  from~\cite{Abouelhoda2012} with permission of the first author}.}
\label{fig:tavaxy}
\end{figure}

}

\section{\correction{Evaluation metrics}}

\label{sec:metrics}

The architectures are
evaluated in Table~\ref{table:evaluation} using five main criteria:
integration complexity, robustness, extensibility, scalability and
\correction{functionality}. Criteria break down into
specific metrics where \emph{lower value indicates better
  performance}. Colors in Table~\ref{table:evaluation} represent
normalized scores (see caption). For each criterion, a global score is
computed by summing up the individual scores for each metric. We
ensure that the different metrics used to calculate the global score
for a criterion are comparable, so that they can be combined
meaningfully.

\correction{The metrics defined hereafter aim at providing a framework
  to evaluate architectures independently from any particular system,
  regardless of any technical constraint such as the use of a specific
  programming language or the internal architecture of the science
  gateway. The goal is to abstract architectural discussions from the
  particular technical context of a real system. Some degree of
  system-specificity can be introduced in the evaluation by assigning
  weights to interactions and components through a public spreadsheet
  available at \url{https://frama.link/LrPRsCQp}\footnote{The
    spreadsheet may need to be downloaded to be edited.}. In
  particular, sheet ``Components and interactions'' in this
  spreadsheet contains the weight assigned to components and
  interactions, which can be used to produce new versions of
  Table~\ref{table:evaluation} that fit the particular technical
  context of a real system. For instance, a high weight could be
  assigned to the science gateway if its internal architecture is such
  that it can hardly be extended in practice.}

\correction{In addition, all the metrics in a criterion contribute
  equally to the global score used for the criterion. Column B of
  sheet ``Metrics'' of the public spreadsheet may be used to assign
  different weights to each metric to adjust the specific context of a
  study.

  The remainder of this Section defines the metrics in each criterion.
}

\begin{table*}
\footnotesize
\centering
\begin{tabular}{rcccccc}
                                     & \textbf{Tight}
                                     & \textbf{Service}
                                     & \textbf{Task}
                                     & \textbf{Pool}
                                     & \textbf{Nested}
                                     & \textbf{Conversion} \\
&&&&& \textbf{\correction{Service+Service}}&\\
\cellcolor[HTML]{EEEEEE}\textbf{Integration complexity}& \multicolumn{6}{l}{\cellcolor[HTML]{EEEEEE}}\\
  Total components -- \texttt{I$_1$} & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99DD99}3
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99BB99}4
                                     & \cellcolor[HTML]{999999}5
                                     & \cellcolor[HTML]{99DD99}3\\
Total interactions -- \texttt{I$_2$} & \cellcolor[HTML]{99FF99}5
                                     & \cellcolor[HTML]{99EE99}6
                                     & \cellcolor[HTML]{99FF99}5
                                     & \cellcolor[HTML]{99DD99}7
                                     & \cellcolor[HTML]{999999}11
                                     & \cellcolor[HTML]{99DD99}7\\
\textbf{Total} (total software pieces) & \cellcolor[HTML]{99FF99}\textbf{7}
                                     & \cellcolor[HTML]{99E899}\textbf{9}
                                     & \cellcolor[HTML]{99FF99}\textbf{7}
                                     & \cellcolor[HTML]{99D299}\textbf{11}
                                     & \cellcolor[HTML]{999999}\textbf{16}
                                     & \cellcolor[HTML]{99DD99}\textbf{10}\\
\cellcolor[HTML]{EEEEEE}\textbf{Robustness}& \multicolumn{6}{l}{\cellcolor[HTML]{EEEEEE}}\\
Specific components -- \texttt{R$_1$} & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99CC99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{999999}2
                                     & \cellcolor[HTML]{999999}2
                                     & \cellcolor[HTML]{99CC99}1\\
  Specific interactions -- \texttt{R$_2$} & \cellcolor[HTML]{99EB99}2
                                     & \cellcolor[HTML]{99D699}3
                                     & \cellcolor[HTML]{99FF99}1
                                     & \cellcolor[HTML]{99C299}4
                                     & \cellcolor[HTML]{999999}6
                                     & \cellcolor[HTML]{99D699}3\\
  \textbf{Total} (execution software pieces)& \cellcolor[HTML]{99F099}\textbf{2}
                                     & \cellcolor[HTML]{99D399}\textbf{4}
                                     & \cellcolor[HTML]{99FF99}\textbf{1}
                                     & \cellcolor[HTML]{99B699}\textbf{6}
                                     & \cellcolor[HTML]{999999}\textbf{8}
                                     & \cellcolor[HTML]{99D399}\textbf{4}\\
\cellcolor[HTML]{EEEEEE}\textbf{Extensibility}& \multicolumn{6}{l}{\cellcolor[HTML]{EEEEEE}}\\
  New engine type -- \texttt{E$_1$}  & \cellcolor[HTML]{99C599}3
                                     & \cellcolor[HTML]{99C599}\correction{3}
                                     & \cellcolor[HTML]{99E299}2
                                     & \cellcolor[HTML]{99C599}3
                                     & \cellcolor[HTML]{999999}4.5
                                     & \cellcolor[HTML]{99FF99}1\\
New engine version -- \texttt{E$_2$} & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{999999}1\\
  New workflow -- \texttt{E$_3$} & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{99FF99}2
                                     & \cellcolor[HTML]{999999}3\\
New infrastructure -- \texttt{E$_4$} & \cellcolor[HTML]{99DD99}4
                                     & \cellcolor[HTML]{99DD99}4
                                     & \cellcolor[HTML]{99FF99}3
                                     & \cellcolor[HTML]{99DD99}4
                                     & \cellcolor[HTML]{999999}6
                                     & \cellcolor[HTML]{99DD99}4\\
  \textbf{Total} (difficulty to extend) & \cellcolor[HTML]{99D299}\textbf{10}
                                     & \cellcolor[HTML]{99E899}\textbf{\correction{9}}
                                     & \cellcolor[HTML]{99FF99}\textbf{8}
                                     & \cellcolor[HTML]{99E899}\textbf{9}
                                     & \cellcolor[HTML]{999999}\textbf{12.5}
                                     & \cellcolor[HTML]{99E899}\textbf{9}\\
\cellcolor[HTML]{EEEEEE}\textbf{Scalability}& \multicolumn{6}{l}{\cellcolor[HTML]{EEEEEE}}\\
Multiple engine instances -- \texttt{S$_1$}& \cellcolor[HTML]{999999}2
                                     & \cellcolor[HTML]{99CC99}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99CC99}1
                                     & \cellcolor[HTML]{99CC99}1\\
Distributed engines -- \texttt{S$_2$}& \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{999999}1\\
Task scheduling -- \texttt{S$_3$}    & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{99FF99}0\\
\textbf{Total} (scalability issues)  & \cellcolor[HTML]{999999}\textbf{3}
                                     & \cellcolor[HTML]{99CC99}\textbf{2}
                                     & \cellcolor[HTML]{99CC99}\textbf{2}
                                     & \cellcolor[HTML]{99FF99}\textbf{1}
                                     & \cellcolor[HTML]{99CC99}\textbf{2}
                                     & \cellcolor[HTML]{99CC99}\textbf{2}\\
\cellcolor[HTML]{EEEEEE}\textbf{\correction{Functionality}}& \multicolumn{6}{l}{\cellcolor[HTML]{EEEEEE}}\\
  Meta-workflow  -- \texttt{\correction{F}$_1$}    & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}\correction{1}
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{99FF99}0\\
  Fine-grained debugging -- \texttt{\correction{F}$_2$}   & \cellcolor[HTML]{99FF99}0
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1
                                     & \cellcolor[HTML]{999999}1\\
  \textbf{Total} (missing features) & \cellcolor[HTML]{99FF99}\textbf{1}
                                     & \cellcolor[HTML]{999999}\textbf{2}
                                     & \cellcolor[HTML]{999999}\textbf{\correction{2}}
                                     & \cellcolor[HTML]{999999}\textbf{2}
                                     & \cellcolor[HTML]{99FF99}\textbf{1}
                                     & \cellcolor[HTML]{99FF99}\textbf{1}\\
\end{tabular}

\caption{Architecture evaluation. Lower values (brighter colors) indicate better performance. Cell color is set as follows: (1) on each row, metric values are
  normalized between 0 (best value) and 1 (worst value):
  $m'=\frac{m-m_{\mathrm{min}}}{m_{\mathrm{max}}-m_{\mathrm{min}}}$ where
  $m$ is the metric value, $m_{\mathrm{min}}$ and $m_{\mathrm{max}}$
  are the minimum and maximum values for all architectures; (2) the RGB hexadecimal color code of the cell
  is \texttt{\#99XX99}, where X=\texttt{round}(F-6m') (\texttt{round} rounds a number to the nearest integer). }
\label{table:evaluation}
\end{table*}

\subsection{\correction{Integration complexity}}

\correction{Integration complexity} is measured through the number of
software components and their interactions. It breaks down into the
following 2 metrics:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Total components (\texttt{I$_1$}): total number of components in
  the architecture.
\item Total interactions (\texttt{I$_2$}): total number of
  interactions in the architecture.
\end{itemize}
One may wonder whether infrastructure should be counted in
\texttt{I$_1$}, since it is usually an external entity that is not
developed nor maintained by the groups who integrate workflow engines
in science gateway. We support its inclusion here because integrating
an infrastructure into the system usually requires some technical
effort (e.g., account creation, software installation, APIs, etc.),
therefore increasing complexity. \correction{The weights given to
  software components in I$_1$ and interactions in I$_2$ can be
  adjusted in the public spreadsheet to cover the technical
  peculiarities of a real system.}

 The two metrics
\correction{I$_1$ and I$_2$} are summed to obtain a global score that
measures the total number of software pieces affected by integration.

\subsection{\correction{Robustness of workflow execution}}

Robustness of workflow execution measures the likelihood that
the workflow execution fails due to errors in the components or in the
interactions of the software architecture. Errors coming from the
infrastructure (e.g., unavailable data or terminated tasks) or
workflows (e.g., wrong user input or application errors) are not
covered, since they do not stem directly from the software
architecture.  Robustness is measured here as a consequence of global
complexity, since complex architectures tend to be more prone to
failure, \correction{in particular in distributed systems where
  interactions between components involve wide-area network
  communications between machines that may be operated by different
  people}. More precisely, robustness is determined by the number of
software components and interactions represented in red in the
architecture diagrams in Figure~\ref{fig:architectures}, which are
specific to workflow execution. Two metrics are used:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Specific components (\texttt{R$_1$}): number of specific
  components involved in workflow executions. \correction{For instance, the
  workflow service is a specific component because its main objective
  is to execute workflows. On the contrary, the science gateway is
  \emph{not} specific to workflow execution since it is used for a
  variety of other functions such as user authentication, data
  transfer, etc.}
\item Specific interactions (\texttt{R$_2$}): number of specific
  interactions involved in workflow executions. \correction{For
    instance, the pool-agent interaction (interaction \texttt{f}) is
    specific to workflow execution while data control (interaction
    \texttt{c$_1$}) is \emph{not} because it is used by the science gateway to transfer
    user data regardless of a particular workflow execution}.
\end{itemize}
\texttt{R$_1$} and \texttt{R$_2$} are
summed to obtain the global score for this criterion, which measures
the total number of software pieces that are specifically involved in
the workflow execution. \correction{The weights given to software components in R$_1$ and interactions in R$_2$ can be adjusted in the public spreadsheet.}

\subsection{\correction{Extensibility}}

Extensibility measures the difficulty to replace or add elements to
the architecture. It is determined by the number of interactions and
components that need to be modified when a new element is
added. Modification of a component is required when its code needs to
be updated or recompiled (science gateway or workflow service), or
when a new piece of software has to be installed (infrastructure
only). Modification of an interaction is deemed necessary when the
parameters involved in this interaction are modified.  Extensibility
breaks down into 4 metrics depending on the type of element (engine,
workflow or infrastructure) that has to be added or replaced:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item New engine (\texttt{E$_1$}): number of interactions or
  components that need to be modified to integrate a new type of
  workflow engine in the architecture. Workflow engines belong to
  different types when they cannot be invoked using the same
  implementation of the interactions.
 \item Engine version upgrade (\texttt{E$_2$}): number of interactions
  or components modified to integrate a new version of a workflow
  engine in the architecture, assuming that another version of the
  same engine type is already available. Different versions of a
  workflow engine can be invoked using the same interaction
  implementation(s). When this is not the case, the different versions
  are considered as different engine types. Components are not treated
  equally regarding engine version updates. Components whose only
  function is to host the workflow engine, i.e., workflow services and
  agents, are not counted in E$_2$ because updates in such components
  are assumed to be straightforward. On the contrary, modifications of
  components that have other functions than wrapping the engine,
  i.e., science gateway and infrastructure, are counted in E$_2$
  because updates in these components require more effort, e.g., new
  release of the science gateway, gaining administrative privileges on
  the infrastructure, etc. In practice, E$_2$=0 when the workflow
  engine is wrapped in a service or in an agent, and E$_2$=1 when it is
  wrapped in another component.  
\item New workflow (\texttt{E$_3$}): number of interactions required
  to integrate a new workflow in the architecture. Adding a new
  workflow is a very common operation that does not require modifying
  software components or interactions, assuming that the engine type
  and version required to execute this workflow are already
  available. In most cases, adding a new workflow requires only
  interactions \texttt{a$_1$} and \texttt{a$_2$}, but \texttt{g}
  is required as well when workflow conversion is used. 
\item New infrastructure (\texttt{E$_4$}): number of interactions or
  components affected for the integration of a new type of infrastructure in
  the architecture. Adding a new infrastructure typically aims at providing more
  computing or storage power, enabling access to specific types of resources
  (e.g., GPUs, clouds), or  enforcing execution policies (e.g.,
  constrain data to remain in a particular network domain).
\end{itemize}
The four metrics are summed to obtain a global score that measures the
difficulty to extend the architecture. \correction{The weights given to software components and interactions in E$_{1-4}$ can be adjusted in the public spreadsheet.} 
Note that some extensions may
affect several metrics in practice. For instance, adding a new type
of engine may help integrating new infrastructures when interactions
\texttt{b} and \texttt{c$_2$} are already present for the new engine
and the infrastructure.

\subsection{\correction{Scalability}}

Scalability corresponds to the ability of an architecture to
cope with high workloads through the following mechanisms: starting multiple engine instances, distributing engines and task scheduling. 
This is measured by assessing the potential
scalability difficulties due to (partial) absence of a given feature in the architecture.  
 Three different features are identified:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Multiple engine instances (\texttt{S$_1$}): measures the
  \correction{ability} for a single gateway instance to use more than
  one engine instance simultaneously, \correction{\emph{each workflow
      being executed by a single engine instance}}.  Workflow engines
  may require important amounts of resources when several workflows,
  or large workflows, are executed. At some point, it may be required
  for the science gateway to distribute the load among several
  engines. \texttt{S$_1$}=0 means that adding a new engine instance is
  inherently supported in the architecture. In this case, elastic
  engines can be implemented through some kind of auto-scaling
  mechanism to control the number of engine instances in the
  architecture. \texttt{S$_1$}=1 means that supporting multiple engine
  instances requires specific developments in the science gateway or
  workflow engine. \texttt{S$_1$}=2 means that new engine instances
  cannot be added.
\item Distributed engines (\texttt{S$_2$}): measures the \correction{ability to distribute}
  the execution \emph{of a single workflow} among different engine
  instances. In our scope, this feature focuses on the capabilities of
  the architecture rather than these of the workflow
  engine. \texttt{S$_2$}=0 means that distributed engines are enabled by
  the architecture, and \texttt{S$_2$}=1 that they require specific
  developments in the workflow engine. 
\item Task scheduling (\texttt{S$_3$}): measures the complexity
  added by the architecture to implement task scheduling on
  the infrastructure. Task
  scheduling typically depends more on the implementation of specific
  algorithms in the science gateway, workflow engine and
  infrastructure than on the architecture used to integrate the
  workflow engine in the science gateway. Some architectures, however,
  complicate the task scheduling problem by introducing additional
  software layers or creating tasks with specific
  characteristics. \texttt{S$_3$}=0 means that the architecture does
  not add any additional complexity to the scheduling problem,
  and \texttt{S$_3$}=1 otherwise.
\end{itemize}
These three metrics are summed to obtain a global measure of the scalability
potential of the architecture.

\subsection{\correction{Functionality}}

\correction{Functionality includes}:
\begin{itemize}[leftmargin=0cm,itemindent=0.35cm,itemsep=0cm]
\item Meta-workflow (\texttt{\correction{F}$_1$}): measures the ability to describe
  meta-workflows from existing workflows. Meta-workflows offer an
  additional level of flexibility to build workflows from reusable
  components. \texttt{\correction{F}$_1$}=0 means that meta-workflows are
  intrinsically enabled by the architecture (i.e., they can be
  implemented using the components and interactions already in place),
  and \texttt{\correction{F}$_1$}=1 means that they may be implemented with some
  development effort.
  
\item Fine-grained debugging (\texttt{\correction{F}$_2$}): availability of
  fine-grained debugging information about workflow tasks (white box
  workflow). \correction{We call ``white box'' workflow a workflow
    where detailed information about individual tasks is available,
    for instance task statuses, execution logs and resource
    consumption. On the contrary, a ``black box'' workflow only
    displays global information such as the workflow status and the
    logs of the workflow engine.} Fine-grained information about
  workflow tasks is required to properly troubleshoot workflow
  executions. \correction{It helps workflow users (scientists)
    identify errors, it allows gateway administrators to troubleshoot
    executions, and it facilitates debugging by workflow
    developers}. \correction{The availability and accuracy of
    fine-grained debugging information} usually depends on the number
  of software layers between the science gateway and the workflow
  engine~\cite{olabarriaga2014}. \texttt{\correction{F}$_2$}=0 means that the
  information is directly accessible in the science gateway,
  \texttt{\correction{F}$_2$}=1 means that it is obtained through one or more
  software interactions.
\end{itemize}
\texttt{\correction{F}$_1$} and \texttt{\correction{F}$_2$} are summed to obtain a total number of missing 
features in the architecture.


%"A Formal Approach to Support Interoperability in Scientific
%Meta-workflows" (reviewed for IWSG and JoGC) has a formal model to
%evaluate CGI and FGI.
%"four major approaches for workflow interoperability include a,b,c,d" (see Terstyanzky et al, "Enabli%ng scientific workflow sharing through CGI...", FGCS 2014) -> read this ref.
% http://www.oreilly.com/programming/free/files/software-architecture-patterns.pdf

\section{\correction{Architecture evaluation}}

\label{sec:evaluation}

The architectures described in Figure~\ref{fig:architectures} are
evaluated \correction{hereafter with the proposed metrics}.

\subsection{Tight integration}

\paragraph{Integration complexity} This architecture does not require any
component in addition to the science gateway and infrastructure
(\texttt{I$_1$=2}) and it involves 5 interactions: \texttt{a$_1$},
\texttt{a$_2$}, \texttt{b}, \texttt{c$_1$} and \texttt{c$_2$}
(\texttt{I$_2$=5}).

\paragraph{Robustness} No component is specific to workflow execution
(\texttt{R$_1$}=0), but interactions \texttt{b} and \texttt{c$_2$} are
(\texttt{R$_2$}=2).

\paragraph{Extensibility} Integrating a new type of workflow engine
requires modifying the science gateway as well as interactions
\texttt{b} and \texttt{c$_2$} (\texttt{E$_1$}=3). Updating a workflow
engine version requires modifications in the science gateway
(\texttt{E$_2$}=1).  Inserting a new workflow is done through
interactions \texttt{a$_1$} and \texttt{a$_2$}
(\texttt{E$_3$}=2). Adding a new infrastructure generates updates in
interactions \texttt{a$_1$}, \texttt{b}, \texttt{c$_1$} and
\texttt{c$_2$} (\texttt{E$_4$}=4).

\paragraph{Scalability} Adding a new engine instance requires a new
instance of the complete science gateway
%, which is in general not possible
(\texttt{S$_1$}=2). 
Specific IT setups such as load-balancing between
web server instances might be used to create new gateway instances, but they would not allow a single gateway instance to use multiple engine instances, which is the point here.
Distributed engines are not available by default
(\texttt{S$_2$}=1). 
The architecture does not add any particular complexity to the task scheduling problem since the workflow engine
may implement any kind of scheduling policy (\texttt{S$_3$}=0).

\paragraph{\correction{Functionality}} Supporting meta-workflows requires
specific developments in the workflow engine or science gateway to
allow workflows to execute other workflows (\texttt{\correction{F}$_1$}=1). For
instance, specific Java objects may be implemented in the science
gateway framework to execute different types of workflows and link
them together.  The science gateway can
retrieve fine-grained debugging information from the workflow engine
directly (\texttt{\correction{F}$_2$}=0).

\subsection{Service invocation}

\paragraph{Integration complexity} Service invocation requires a workflow service
in addition to the science gateway and infrastructure
(\texttt{I$_1$}=3). The architecture involves 6 interactions:
\texttt{a$_1$}, \texttt{a$_2$}, \texttt{b}, \texttt{c$_1$},
\texttt{c$_2$} and \texttt{d} (\texttt{I$_2$}=6).

\paragraph{Robustness} The workflow service is a component specific to
workflow execution (\texttt{R$_1$}=1). Workflow execution also
involves 3 specific interactions: \texttt{b},
\texttt{c$_2$} and \texttt{d} (\texttt{R$_2$}=3).

\paragraph{Extensibility} Adding a new type of workflow engine
requires implementing the corresponding workflow service,  modifying
interaction \texttt{d}, and  implementing interactions \texttt{b} and
\texttt{$c_2$}. \correction{However, when a new type of workflow engine is added, it is always possible to reuse either an existing available workflow service or interaction \texttt{d} (when a new workflow service has to be developed). Therefore, \texttt{E$_1$}=3}. New engine versions can be added by
updating the workflow service without modifying any interaction or
component (\texttt{E$_2$}=0). Updating the engine version in a
workflow service does not count in \texttt{E$_2$} since the only goal of this component
is to wrap the engine.  New workflows are added in the science gateway
or in the workflow engine through interactions \texttt{a$_1$} and
\texttt{a$_2$} (\texttt{E$_3$}=2). Adding a new type of infrastructure
requires updates in interactions \texttt{a$_1$}, \texttt{b},
\texttt{$c_1$} and \texttt{$c_2$} (\texttt{E$_4$}=4).

\paragraph{Scalability} The service architecture in principle supports
multiple engine instances through multiple workflow services. Adding a
new engine instance, however, requires specific developments in the science gateway
(\texttt{S$_1$}=1). Distributing the execution of a single workflow in multiple
engines is usually not possible unless the workflow engine has
specific abilities (\texttt{S$_2$}=1).

\paragraph{\correction{Functionality}} Meta-workflows require specific
developments in the workflow engine or science gateway to allow
workflows to execute other workflows.  (\texttt{\correction{F}$_1$}=1).
 The
science gateway needs to invoke interaction \texttt{d} to retrieve
fine-grained debugging information from the workflow service
(\texttt{\correction{F}$_2$}=1).

\subsection{Task encapsulation}

\paragraph{Integration complexity} Task encapsulation requires only 2
components (\texttt{I$_1$}=2).  It involves 5 interactions:
\texttt{a$_1$}, \texttt{a$_2$}, \texttt{b}, \correction{\texttt{c$_1$}} and
\texttt{e} (\texttt{I$_2$}=5).

\paragraph{Robustness} No component is specific to workflow execution
(\texttt{R$_1$}=0), and only interaction \texttt{e} is necessary
(\texttt{R$_2$}=1).

\paragraph{Extensibility} Integrating a new type of workflow engine
requires developing interaction \texttt{e} and  installing the engine
on the infrastructure (\texttt{E$_1$}=2). Updating an engine version
in the architecture shares the same mechanism as version updates of
other tasks, which requires an update on the
infrastructure (\texttt{E$_2$}=1).  New workflows are integrated by
creating a new task in the science gateway through interactions
\texttt{a$_1$} and \texttt{a$_2$} (\texttt{E$_3$}=2). Adding a new
infrastructure requires updating interactions \texttt{a$_1$},
\texttt{b} and \correction{\texttt{c$_1$}} in the science gateway (\texttt{E$_4$}=3).

\paragraph{Scalability}
New engine instances are spawned and executed on the infrastructure as
any other task upon user submission (\texttt{S$_1$}=0). This is a
major interest of task encapsulation. Distributed engines are not
supported by default (\texttt{S$_2$}=1). Task scheduling is slightly
more complex than in the other approaches due to the special role of
the task that executes the workflow engine (\texttt{S$_3$}=1). 
Indeed,
the reliability of this task is critical since all the sub-tasks in
the workflow depend on it and, depending on the recovery capabilities
of the workflow engine, may need to be resubmitted if the workflow
task fails. The workflow task is also longer than all its sub-tasks,
which increases its chances of failure. In addition, task parameters,
for instance estimated walltime, are more difficult to estimate for
the workflow task than for the sub-tasks because workflows are by
definition more complex than their sub-tasks: errors on sub-task
parameter estimations accumulate in the workflow, and additional
control constructs such as tests and loops may further increase the
uncertainty. Such parameter estimation errors may generate issues such
as selection of wrong batch queues on clusters or task termination due
to exceeded quotas. Finally, the interdependencies between
the workflow task and its sub-tasks may create deadlocks when there is
contention. For instance, if only 1 computing resource is available
for the science gateway and if the workflow task is running on it and
submits sub-tasks, then the sub-tasks could only execute when the
resource is available, which will never happen because the workflow
task will not complete until the sub-tasks complete. This
configuration can be generalized to an infrastructure with $n$
resources where $n$ workflows are submitted. In practice, however, the
number of submitted workflows usually remains lower than the number of
computing resources available on this infrastructure, which makes such
deadlocks unlikely to happen. 

\paragraph{\correction{Functionality}} Task encapsulation
\correction{does not enable meta-workflows by default
  (\texttt{\correction{F}$_1$=1})}. Fine-grained debugging information is obtained
through interaction \texttt{b} (\texttt{\correction{F}$_2$}=1).

\subsection{Pool model}

\paragraph{Integration complexity} The pool model requires a workflow pool and an
agent in addition to the science gateway and infrastructure
(\texttt{I$_1$=4}). It involves 7 interactions: \texttt{a$_1$},
\texttt{a$_2$}, \texttt{b}, \texttt{c$_1$}, \texttt{c$_2$}, \texttt{d}
and \texttt{f} (\texttt{I$_2$}=7).

\paragraph{Robustness} The workflow pool and agent are specific to
workflow execution (\texttt{R$_1$=2}). Interactions \texttt{b},
\texttt{c$_2$}, \texttt{d} and \texttt{f} also are (\texttt{R$_2$=4}).

\paragraph{Extensibility} Adding a new engine type requires wrapping
the engine into the agent and updating interactions \texttt{b} and
\texttt{c$_2$} (\texttt{E$_1$=3}). Updating the version of an engine
is transparent (\texttt{E$_2$=0}) since it only requires updating the
agent, which is a component dedicated to the engine. Integrating a new workflow is
done through interactions \texttt{a$_1$} and \texttt{a$_2$}
(\texttt{E$_3$=2}). Integrating a new infrastructure requires updates
in interactions \texttt{a$_1$}, \texttt{b}, \texttt{c$_1$} and \texttt{c$_2$}
(\texttt{E$_4$=4}).

\paragraph{Scalability} By design, new engine instances only require
new agents, which can be easily automated (\texttt{S$_1$=0}). Distributed engines are not available
by default (\texttt{S$_2$=1}) and the architecture does not add any
complexity to the task scheduling problem (\texttt{S$_3$=0}).

\paragraph{\correction{Functionality}} Meta-workflows require specific
developments in the workflow engine to enable workflow submission
(\texttt{\correction{F}$_1$=1}). Debugging information is accessed through
interactions \texttt{d} and \texttt{f} (\texttt{\correction{F}$_2$=1}).

\subsection{Nested workflows with service invocation}

\paragraph{Integration complexity} Setting up a nested workflow
architecture with service invocation requires a science gateway, 2
workflow services and 2 infrastructures (\texttt{I$_1$=5}). The
architecture involves 11 interactions (\texttt{I$_2$=11}):
\texttt{a$_1$} (twice), \texttt{a$_2$}, \texttt{b} (twice), \texttt{c$_1$} (twice),
\texttt{c$_2$} (twice) and
\texttt{d} (twice).

\paragraph{Robustness} The two workflow services are specific to
workflow execution (\texttt{R$_1$=2}). Interactions \texttt{b}
(twice), \texttt{c$_2$} (twice) and \texttt{d} (twice) also
are necessary (\texttt{R$_2$=6}).

\paragraph{Extensibility} Adding a new type of \emph{parent} engine
requires implementing the corresponding service,  implementing
interactions \texttt{b} and \texttt{c$_2$} in the parent engine, and
implementing interaction \texttt{d} in the science gateway and in the
parent service (\texttt{E$_1$=5}). Adding a new type of \emph{child}
engine only requires implementing the corresponding service, 
developing interactions \texttt{b} and \texttt{c$_2$} in the child
engine, and implementing interaction \texttt{d} in the parent service
(\texttt{E$_1$=4}). We use \texttt{E$_1$=4.5} in
Table~\ref{table:evaluation} to reflect both conditions. Adding a new
version in the parent or child engine only requires modifying this
engine (\texttt{E$_2$=0}). Adding a new workflow is done through
interaction \texttt{a$_1$} and \texttt{a$_2$}
(\texttt{E$_3$=2}). Adding a new infrastructure requires 
re-implementing interactions \texttt{a$_1$}, \texttt{b} and
\texttt{c$_2$} twice, and interaction \texttt{c$_1$} once so that it
can be supported by both workflow engines (\texttt{E$_4$=6}).

\paragraph{Scalability} As in the service architecture, adding a new
engine instance requires specific developments in the science gateway
(instance of a parent engine), or in the parent engine (instance of a
child engine) (\texttt{S$_1$=1}). Similarly, elastic engines are
difficult to achieve. Distributed engines can be implemented through meta-workflows (\texttt{S$_2$=0}). Task scheduling
is more complex than in other architectures though, due to the fact
that workflow execution is split in different engines (\texttt{S$_3$=1}).

\paragraph{\correction{Functionality}}
Meta-workflows can be implemented, which is one of the main interest
of this architecture (\texttt{\correction{F}$_1$=0}). Note, however, that the
complexity of the architecture increases with the number of engine
types involved in meta-workflows: for instance, a meta-workflow with
child workflows executed by 2 different types of engines would require
an additional workflow service and the corresponding interactions.
Debugging information is accessed through interaction \texttt{d}
(invoked twice) (\texttt{\correction{F}$_2$=1}).

\subsection{Workflow conversion with service invocation}

\paragraph{Integration complexity} Workflow conversion with service invocation
requires the same components as for service invocation
(\texttt{I$_1$}=3), and an additional \texttt{g} interaction (\texttt{I$_1$}=7).

\paragraph{Robustness} Since workflow conversion is not involved in
the execution (it is an offline process), the scores are the same as for the
service architecture (\texttt{R$_1$=1}, \texttt{R$_2$=3}).

\paragraph{Extensibility} Since adding a new type of workflow engine
aims at supporting more workflows, we consider that it only requires
re-implementing interaction \texttt{g} in this architecture  (\texttt{E$_1$=1}). Note,
however, that implementing interaction \texttt{g} can require
substantial work depending on the complexity of the workflow language used by
the new engine. Similarly, adding a
new engine version only requires modifying interaction \texttt{g}
(\texttt{E$_2$=1}).  Adding a new workflow is done through
interactions \texttt{a$_1$}, \texttt{a$_2$} and \texttt{g} (\texttt{E$_3$=3}). As in the
service architecture, interfacing with a new infrastructure requires
modifications in interactions \texttt{a$_1$}, \texttt{b}, \texttt{c$_1$}
and \texttt{c$_2$} (\texttt{E$_4$=4}).

\paragraph{Scalability}  Since workflow conversion is not involved in
the execution (it is an offline process), the score is the same as for the
service architecture (\texttt{S$_1$=1},
\texttt{S$_2$=1}, \texttt{S$_3$=0}).

\paragraph{\correction{Functionality}} Meta-workflows are available after
conversion, by connecting workflows in the language used in the
science gateway (\texttt{\correction{F}$_1$=0}).  Debugging information is accessible
as in the service invocation architecture (\texttt{\correction{F}$_2$=1}).

\section{Discussion}
\label{sec:discussion}
\subsection{Comparison between architectures}

Tight integration and task encapsulation are the simplest
architectures to integrate, followed by service integration, workflow conversion (with
service invocation) and pool. Nested workflows (with service
invocation) require more integration than the other
architectures. Robustness roughly leads to the same ordering of
architectures, with tight integration and task encapsulation in the top
group, service integration and workflow conversion (with service
invocation) close behind, pool in a third group, and nested workflows
(with service invocation) at the end. This ordering is consistent
across metrics; it reflects the global complexity of the
architectures.

Regarding extensibility, most architectures are overall comparable,
except nested workflows (with service invocation) which are
significantly behind. This is explained by the complexity of the
nested workflow architecture, with 2 infrastructures and 2 workflow
services. Task encapsulation and workflow conversion (with service
invocation) perform slightly better when integrating new engines
(\texttt{E$_1$}), which makes them useful architectures for science
gateways that do not focus on a particular engine.  However, task encapsulation, workflow conversion (with
service invocation) and tight integration perform worse than the
others when adding engine versions (\texttt{E$_2$}), due to the need
to update infrastructure (task encapsulation), science gateway (tight
integration), or workflow converter (workflow conversion). Workflow conversion
performs worse than the others when integrating new workflows
(\texttt{E$_3$}) because of the language conversion step. All
architectures except nested workflows are equivalent when integrating
new infrastructures (\texttt{E$_4$}).

The pool architecture is overall the most scalable, which is not
surprising since it is designed precisely for scalability. Tight
integration is the least scalable and all the other architectures
perform the same overall. The global scalability score, however,
should not conceal the unique characteristics of architectures regarding
this criterion. Nested workflows are the only architecture that can
easily accommodate distributed workflow execution, which can be
critical in some cases. At the same time, the scheduling constraints
created by task encapsulation and nested workflows may become problematic  depending on the type of targeted
infrastructure. Non-reliable infrastructures,
for example, could hardly cope with workflow engines being wrapped in
computing tasks as done in task encapsulation. The availability of
multiple engine instances could also become a critical feature for
science gateways with important workloads, which would favor task
encapsulation and pool.

Differences in \correction{functionality} should not be
neglected. Nested workflows (with service invocation) and workflow
conversion (with service invocation) are the only architectures that
intrinsically support meta-workflows. Besides, tight integration is
the only architecture that allows fine-grained debugging, which may be
critical for efficient user support.

Table~\ref{table:overall} provides an overall comparison between
architectures, based on the metrics in Table~\ref{table:evaluation}.
\correction{It should be noted} that this analysis is only meant for illustration purposes, since
it assumes that all criteria have equal weights while real systems
would favor some of them. \correction{Weights can be adjusted in the
  public spreadsheet at \url{https://frama.link/LrPRsCQp} (column B of
  sheet ``Metrics'') to produce a custom version of
  Table~\ref{table:overall} if required.}

Overall, task encapsulation \correction{and workflow conversion} perform a bit
better than the other architectures and nested workflows stand a bit
behind for the reasons mentioned previously.
\begin{table*}
\footnotesize
\centering
\begin{tabular}{rcccccc}
                                    & \textbf{Tight}
                                    & \textbf{Service}
                                    & \textbf{Task}
                                    & \textbf{Pool}
                                    & \textbf{Nested}
                                    & \textbf{Conversion} \\
                                    &&&&& \textbf{\correction{Service+Service}}&\\
  Integration (global score)    &
                                    \cellcolor[HTML]{99FF99}{0.00}
                                    & \cellcolor[HTML]{99E899}{0.22}
                                    & \cellcolor[HTML]{99FF99}{0.00}
                                    & \cellcolor[HTML]{99D299}{0.44}
                                    & \cellcolor[HTML]{999999}{1.00}
                                      & \cellcolor[HTML]{99DD99}{0.33}\\
Robustness (global score) &
                                \cellcolor[HTML]{99F099}{0.14}
                                    & \cellcolor[HTML]{99D399}{0.43}
                                    & \cellcolor[HTML]{99FF99}{0.00}
                                    & \cellcolor[HTML]{99B699}{0.71}
                                    & \cellcolor[HTML]{999999}{1.00}
                                    & \cellcolor[HTML]{99D399}{0.43}\\
  Extensibility (global score)  & \cellcolor[HTML]{99D299}{0.44}
                                     & \cellcolor[HTML]{99E899}{\correction{0.22}}
                                     & \cellcolor[HTML]{99FF99}{0.00}
                                     & \cellcolor[HTML]{99E899}{0.22}
                                     & \cellcolor[HTML]{999999}{1.00}
                                     & \cellcolor[HTML]{99E899}{0.22}\\
Scalability (global score)  & \cellcolor[HTML]{999999}{1.00}
                                     & \cellcolor[HTML]{99CC99}{0.50}
                                     & \cellcolor[HTML]{99CC99}{0.50}
                                     & \cellcolor[HTML]{99FF99}{0.00}
                                     & \cellcolor[HTML]{99CC99}{0.50}
                                     & \cellcolor[HTML]{99CC99}{0.50}\\
\correction{Functionality} (global score) & \cellcolor[HTML]{99FF99}{0.00}
                                     & \cellcolor[HTML]{999999}{1.00}
                                     & \cellcolor[HTML]{999999}{\correction{1.00}}
                                     & \cellcolor[HTML]{999999}{1.00}
                                     & \cellcolor[HTML]{99FF99}{0.00}
                                     & \cellcolor[HTML]{99FF99}{0.00}\\
                                    & \cellcolor[HTML]{99FA99}\textbf{1.6}
                                    & \cellcolor[HTML]{99D299}\textbf{\correction{2.4}}
                                    & \cellcolor[HTML]{99FE99}\textbf{\correction{1.5}}
                                    & \cellcolor[HTML]{99D299}\textbf{2.4}
                                    & \cellcolor[HTML]{999999}\textbf{3.5}
                                    & \cellcolor[HTML]{99FF99}\textbf{1.5}\\
\end{tabular}
\caption{Overall evaluation. Brighter colors and lower scores indicate better performance. Scores
  are obtained by summing the normalized global scores ($m'$ values) of
  each criterion in Table~\ref{table:evaluation} and the colors are obtained as in Table~\ref{table:evaluation}. }
\label{table:overall}
\end{table*}

\subsection{Limitations}


A few limitations should be considered when using the results of our
evaluation. First, our evaluation methods aimed to provide comparative
metrics, however the high-level of abstraction used to derive these
metrics hinders the complexity of real systems to some
extent. In particular, the
presented architectures are abstract patterns that may be mixed
together in actual systems. The distinction between tight integration and
service invocation, for instance, may not always be that clear in
practice. Service invocation may also be combined with task
encapsulation in some cases. Nevertheless, the criteria discussed in this
work would still be applicable for broadly comparing and categorizing such cases of
hybrid architectures.

\correction{It should also be noted} that all the interactions
involved in the architectures were treated equally, whereas some of
them are obviously more complex than others. For example, interaction
\texttt{g} (workflow language conversion) is clearly more complex than
interaction \texttt{d} (service invocation). However, without entering
into the details of a particular system, quantification of the
robustness or the amount of development associated with each
interaction and software component will hardly be
precise. \correction{If a particular system is evaluated, the public
  spreadsheet can be used to adjust the weights given to specific
  components and interactions based on the technical context.}

The particular case of interaction \texttt{g} (workflow language
conversion) requires particular attention when implementing a real
system since this interaction may not be easily generalized to any
workflow language. For instance, converting FSL, PSOM or Nipype
pipelines to any other workflow language is problematic because these
engines rely on general-purpose programming languages such as Bash,
Octave/Matlab and Python, which are much richer than scientific
workflow languages. \correction{If not properly validated, workflow
  language conversion could introduce critical errors impacting the
  robustness and correctness of the execution. }

The abstract nested workflows and workflow conversion patterns were
instantiated with service invocation so that they can be analyzed in
the same framework as the other architectures. Other types of
instantiation, for instance nested workflows with task encapsulation,
could also be envisaged. We chose to limit ourselves to instantiations
with service invocation because the resulting architectures have already been
implemented in real systems, and because service invocation is largely
used. Nevertheless, it could be interesting to explore other types of
instantiations.

The particular technical or historical context of a science gateway
project may also influence the \correction{evaluation} of an
architecture to integrate workflow engines. For instance, many
workflow engines are already available as web services, which tends to
favor service invocation (\correction{in particular when interactions
  can be re-purposed}), and other science gateways may have strongly
tested task and data control features (interactions \texttt{b} and
\correction{\texttt{c$_1$}}), which would favor task
encapsulation. Similarly, adding a new type of engine may facilitate
integration of a new infrastructure when interactions \texttt{b} and
\texttt{c$_2$} are already available. The migration cost between
architectures has been ignored as well.

Finally, workflow engines are only one of the many aspects involved in
the design of a science gateway. Other properties definitely influence
the design of a software architecture, for instance collaborative
features, data visualization, search, authentication, accounting and
so on.

\correction{\section{Application to systems design}}
\label{sec:application}

\correction{To illustrate how our evaluation framework can be applied
  to help design new systems, let's consider a hypothetical system
  where the workflow engine is split in two parts: (1) a high-level
  part integrated in the science gateway, which submits sub-workflows
  to the infrastructure; (2) a lower-level part, executed on the
  infrastructure, which executes the sub-workflows. This scenario came
  up after the evaluation framework had already been designed.

  We model such a system using a nested workflow architecture with a
  ``Tight+Task'' instantiation, i.e., the parent engine is tightly
  integrated in the science gateway and the child engine is integrated
  through task encapsulation.  Figure~\ref{fig:nested-3} shows the
  graphical representation of the system. From this representation we
  find that the sub-tasks submitted by the child engine through
  interaction \texttt{e} should be handled by the parent engine rather
  than by the science gateway. Indeed, handling the tasks directly in
  the science gateway would lead to create a new specific interaction,
  named, e.g., \texttt{b$_1$}, while \texttt{b} could be reused. We
  also find that interaction \texttt{e} allows running the sub-tasks
  on the infrastructure(s) supported by the parent engine with no
  further development effort required in the child engine.

  The system evaluation is presented in
  Table~\ref{table:evaluation-2}. The detailed calculations are
  available in our public spreadsheet at
  \url{https://frama.link/LrPRsCQp}. We conclude that the studied system
  supports nested workflows with a much better performance than the
  nested workflow model instantiated with service invocation
  (evaluated in Table~\ref{table:evaluation}): the integration score
  is improved by a factor of 2, robustness is improved by a factor of
  2.6, extensibility is substantially improved, scalability and
  functionality are not penalized.  }

\begin{figure}
  \centering
  \def\svgwidth{0.5\columnwidth}
  \input{figures/nested-3.pdf_tex}
\caption{\correction{Nested workflow architecture instantiated with tight integration and task encapsulation (Tight+Task).}}
\label{fig:nested-3}
\end{figure}

\begin{table}
\footnotesize
\centering
\begin{tabular}{rc}
                                     & \textbf{Nested}\\
                                     & \textbf{Tight+Task}\\
\cellcolor[HTML]{EEEEEE}\textbf{Integration complexity}&\cellcolor[HTML]{EEEEEE}\\
  Total components -- \texttt{I$_1$} & 2\\
Total interactions -- \texttt{I$_2$} & 6\\
\textbf{Total}& \textbf{8}\\
\cellcolor[HTML]{EEEEEE}\textbf{Robustness}&\cellcolor[HTML]{EEEEEE}\\
Specific components -- \texttt{R$_1$} & 0\\
  Specific interactions -- \texttt{R$_2$} & 3\\
  \textbf{Total}& \textbf{3}\\
\cellcolor[HTML]{EEEEEE}\textbf{Extensibility}&\cellcolor[HTML]{EEEEEE}\\
  New engine type -- \texttt{E$_1$}  & 3\\
New engine version -- \texttt{E$_2$} & 1\\
  New workflow -- \texttt{E$_3$}     & 2\\
New infrastructure -- \texttt{E$_4$} & 4\\
  \textbf{Total}& \textbf{10}\\
\cellcolor[HTML]{EEEEEE}\textbf{Scalability}& \cellcolor[HTML]{EEEEEE}\\
Multiple engine instances -- \texttt{S$_1$}& 1\\
Distributed engines -- \texttt{S$_2$}& 0\\
Task scheduling -- \texttt{S$_3$}    & 1\\
\textbf{Total}& \textbf{2}\\
\cellcolor[HTML]{EEEEEE}\textbf{\correction{Functionality}}&\cellcolor[HTML]{EEEEEE}\\
  Meta-workflow  -- \texttt{\correction{F}$_1$}    & 0\\
  Fine-grained debugging -- \texttt{\correction{F}$_2$}  & 1\\
  \textbf{Total}& \textbf{1}\\
\end{tabular}
\caption{\correction{Evaluation of the nested workflow architecture instantiated with tight integration (parent engine) and task encapsulation (child engine).}}
\label{table:evaluation-2}
\end{table}

\section{Related work}
\label{sec:related}
 
There is abundant literature describing specific workflow engines and
systems; some of the main references are cited in
Section~\ref{sec:introduction-engines}. A few works described the
architecture and features of workflow systems at an abstract level. For
instance, the early work~\cite{yuTaxonomy} proposes a generic
architecture for grid workflow systems that is based on the workflow
reference model defined by the Workflow Management
Coalition\footnote{\url{http://www.wfmc.org}}.  Deelman et
al. \cite{deelman2009workflows} have further characterized the
features of workflow systems. These two works, however, do not mention
science gateways.

Numerous science gateways have been described, as mentioned in
Section~\ref{sec:intro_sg}. However, only a few works focused on
science gateway architectures. Shahand et al.~\cite{shahand:2015ab}
presents the Science Gateway Canvas, which is a business reference
model where the most relevant functional components are organized into
functional groups. Although workflow management is mentioned as a
possible component to coordinate distributed computations in science
gateways, the paper does not comment on architecture to achieve this.

Olabarriaga et al.~\cite{olabarriaga2014} presents a user-centered
view of the ecosystem of science gateways with focus on workflow
management. Their proposed layered system architecture includes
gateway, workflow engine and distributed infrastructure components,
similarly to the ``service invocation'' pattern. However other patterns
are not identified.

\section{Conclusion}

% Summary of contributions
We have systematically reviewed architectures used to integrate
workflow engines in science gateways. These architectures were
described in a system-independent framework suitable for comparison,
illustrated on real systems, and evaluated using novel quantitative
metrics that allow simple comparison across architectures. We have
discussed the pros and cons of all the presented architectures based
on these metrics, \correction{and we have shown how our evaluation
  framework can be leveraged in the design of new systems}.

% Impact of the work
To the best of our knowledge, our work is the first to systematically
review and compare software architectures  to integrate workflow
engines into science gateways. So far, the literature on science gateways and
workflow engines has focused on the description of particular systems,
or on the presentation of a particular architecture.  Instead, our
analysis abstracts and evaluates architectural patterns independently
from any particular system, providing general insight about ways to integrate
science gateways and workflow engines. These insights will be valuable
for software architects when considering alternatives for the architecture and evaluating the impact of their decisions.

% Literature on SG architecture Very few works go beyond the
% description of architectures of particular systems. For instance, the work
%in~\cite{Gannon2005} discusses service-oriented architectures for
% science gateways with workflow engines.  The work in
% http://link.springer.com/chapter/10.1007/11596141_3 discusses
% service-oriented architectures for science gateways, with a workflow
% engine. The work in
% http://docs.lib.purdue.edu/cgi/viewcontent.cgi?article=1414&context=nanopub
% highlights 4 TeraGrid science gateways (GridChem, LEAD, nanoHUB,
% CABIG). Architectures are described but there is no real focus on
% workflow engines. GridChem doesn't include any workflow engine,
% which btw make it relevant for integration via sub-tasking. LEAD has
% a workflow engine.

\section{Acknowledgments}

\correction{We thank the anonymous reviewers for the thorough reviews and useful comments that greatly contributed to improve the quality of this paper.} This work has been made possible with the support of the Irving Ludmer
Family Foundation and the Ludmer Centre for Neuroinformatics and
Mental Health. The integration between PSOM and CBRAIN was supported
by a Brain Canada Platform Support Grant, as well as the Canadian
Consortium on Neurodegeneration in Aging (CCNA), through a grant from
the Canadian Institute of Health Research and funding from several
partners.  This work is in the scope of the LABEX PRIMES (ANR-11-
LABX-0063) of Universit\'e de Lyon, within the program
``Investissements d'Avenir'' (ANR-11-IDEX-0007) operated by the French
National Research Agency (ANR). This work also falls into the scope of
the scientific topics of the French National Grid Institute (IdG). The
VIP team thanks the site administrators of the European Grid
Initiative and the GGUS support for their help related to the VIP
platform. The CBRAIN team is grateful for the computing cycles,
storage, and support obtained from Compute Canada
(\url{https://computecanada.ca}) and platform development program from
CANARIE (\url{http://www.canarie.ca/}). We also acknowledge the Dutch
national e-Infrastructure with the support of SURF Cooperative, the
Dutch national program COMMIT/ and the High Performance Computing and
Networking (HPCN) Fund of the University of Amsterdam for their
support to the science gateway actitivies at the AMC.  We are also
grateful to the financial support provided by FP7 E-INFRASTRUCTURE
program for financial support to SCI-BUS, SHIWA and ER-flow
projects. 

\section*{References}

\enlargethispage{5mm}
\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
\endinput
